abline(v=stats1@alpha.values[[1]][1155], lty=2, col=4)
# Calculate the new confusion matrix.
precision(stats1@alpha.values[[1]][1155])
which.max(stats1@x.values[[1]]+stats1@y.values[[1]])
stats1@alpha.values[[1]][1245]
# Add these pieces to the graph
stats1@x.values[[1]][1245]
stats1@y.values[[1]][1245]
abline(v=stats1@alpha.values[[1]][1245], lty=3, col='seagreen', lwd=2)
# Calculate the new confusion matrix.
precision(stats1@alpha.values[[1]][1245])
library(DAAG)
cv.binary(mylogit)
mydataRF<- read.csv("C:/Users/dkane/Documents/R Packages/Marion County/recidivism4d.csv")
attach(mydataRF)
mydataRF$Gender <- as.factor(mydataRF$Gender)
mydataRF$NonWhite <- as.factor(mydataRF$NonWhite)
mydataRF$Felony5 <- as.factor(mydataRF$Felony5)
mydataRF$FTAEver <- as.factor(mydataRF$FTAEver)
mydataRF$Employment <- as.factor(mydataRF$Employment)
mydataRF$FelonyType <- as.factor(mydataRF$FelonyType)
mydataRF$CaseCharge <- as.factor(mydataRF$CaseCharge)
mydataRF$NewJailAdmission <- as.factor(mydataRF$NewJailAdmission)
mydataRF$ZipCode <- as.factor(mydataRF$ZipCode)
library(randomForest)
RandomForestModel <- randomForest(NewJailAdmission ~ Felony5 + Month.at.Address + FTAEver + Employment+ Age + Gender + PriorMisdmr + NonWhite + FelonyType + Priors + PriorFelonies + ChargeClass + CaseCharge + DrugCharge + PropertyCharge + PersonalCharge, data=mydataRF, ntree=5000, mtry=5, importance=TRUE)
print(RandomForestModel)
importance(RandomForestModel)
plot.new()
varImpPlot(RandomForestModel, type=1, pch=19, col=1, cex=1.0, main="")
abline(v=10, col="blue")
plot.new()
varImpPlot(RandomForestModel, type=1, pch=19, col=1, cex=1.0, main="")
abline(v=35, col="blue")
plot.new()
varImpPlot(RandomForestModel, type=1, pch=19, col=1, cex=1.0, main="")
abline(v=30, col="blue")
set.seed(1234)
ind <- sample(2, nrow(mydata), replace=TRUE, prob=c(1, 0))
trainData <- mydata[ind==1,]
testData <- mydata[ind==2,]
mylogit <- glm(FTA ~ FelonyIndicator + PersonalCharge + ChargeClass + DrugCharge +
Gender + PropertyCharge + NumofMisdmr + Age +
NumofCaseCharge, data = trainData, family = "binomial")
summary(mylogit)
anova(mylogit, test="Chisq")
mydataRF<- read.csv("C:/Users/dkane/Documents/R Packages/Marion County/recidivism4e2.csv") #recidivism4d
attach(mydataRF)
RandomForestModel <- randomForest(NewJailAdmission ~ Felony5 + Month.at.Address + FTAEver + Employment+ Age + Gender + PriorMisdmr + NonWhite + FelonyType + Priors + PriorFelonies + ChargeClass + CaseCharge + DrugCharge + PropertyCharge + PersonalCharge, data=mydataRF, ntree=500, mtry=5, importance=TRUE)
print(RandomForestModel)
importance(RandomForestModel)
library(randomForest)
RandomForestModel <- randomForest(NewJailAdmission ~ Felony5 + Month.at.Address + FTAEver + Employment+ Age + Gender + PriorMisdmr + NonWhite + FelonyType + Priors + PriorFelonies + ChargeClass + CaseCharge + DrugCharge + PropertyCharge + PersonalCharge, data=mydataRF, ntree=500, mtry=5, importance=TRUE)
print(RandomForestModel)
importance(RandomForestModel)
RandomForestModel <- randomForest(NewJailAdmission ~ ChargeClass + Month.at.Address + FTAEver + FTA + Employment+ Age + Gender + NumofMisdmr + NonWhite + FelonyIndicator + NumofPriors + NumofFelonies + NumofCaseCharge + DrugCharge + PropertyCharge + PersonalCharge, data=mydataRF, ntree=500, mtry=5, importance=TRUE)
print(RandomForestModel)
importance(RandomForestModel)
plot.new()
plot(RandomForestModel, log="y")
varImpPlot(RandomForestModel)
plot.new()
plot.new()
plot(RandomForestModel, log="y")
varImpPlot(RandomForestModel)
plot.new()
varImpPlot(RandomForestModel, type=1, pch=19, col=1, cex=1.0, main="")
abline(v=30, col="blue")
plot.new()
plot.new()
varImpPlot(RandomForestModel, type=1, pch=19, col=1, cex=1.0, main="")
abline(v=12, col="blue")
plot.new()
varImpPlot(RandomForestModel, type=1, pch=19, col=1, cex=1.0, main="")
abline(v=8, col="blue")
plot.new()
varImpPlot(RandomForestModel, type=1, pch=19, col=1, cex=1.0, main="")
abline(v=9, col="blue")
varImpPlot(RandomForestModel, type=2, pch=19, col=1, cex=1.0, main="")
print(RandomForestModel)
importance(RandomForestModel)
plot.new()
plot(RandomForestModel, log="y")
varImpPlot(RandomForestModel)
plot.new()
varImpPlot(RandomForestModel, type=1, pch=19, col=1, cex=1.0, main="")
abline(v=9, col="blue")
mydataRF<- read.csv("C:/Users/dkane/Documents/R Packages/Marion County/recidivism4e2.csv") #recidivism4d
attach(mydataRF)
library(randomForest)
RandomForestModel <- randomForest(NewJailAdmission ~ ChargeClass + Month.at.Address + FTAEver + FTA + Employment+ Age + Gender + NumofMisdmr + NonWhite + FelonyIndicator + NumofPriors + NumofFelonies + NumofCaseCharge + DrugCharge + PropertyCharge + PersonalCharge, data=mydataRF, ntree=500, mtry=5, importance=TRUE)
print(RandomForestModel)
importance(RandomForestModel)
plot.new()
plot(RandomForestModel, log="y")
varImpPlot(RandomForestModel)
plot.new()
varImpPlot(RandomForestModel, type=1, pch=19, col=1, cex=1.0, main="")
abline(v=9, col="blue")
varImpPlot(RandomForestModel, type=2, pch=19, col=1, cex=1.0, main="")
RandomForestModel <- randomForest(NewJailAdmission ~ ChargeClass + Month.at.Address + FTAEver + FTA + Employment+ Age + Gender + NumofMisdmr + NonWhite + FelonyIndicator + NumofPriors + NumofFelonies + NumofCaseCharge + DrugCharge + PropertyCharge + PersonalCharge, data=mydataRF, ntree=500, mtry=5, importance=TRUE)
print(RandomForestModel)
print(RandomForestModel)
importance(RandomForestModel)
mydata<- read.csv("C:/Users/dkane/Documents/R Packages/Marion County/recidivism4e2.csv")
attach(mydata)
library(aod)
library(ggplot2)
library(reshape2)
library(car)
library(corrplot)
set.seed(1234)
ind <- sample(2, nrow(mydata), replace=TRUE, prob=c(1, 0))
trainData <- mydata[ind==1,]
testData <- mydata[ind==2,]
mylogit <- glm(FTA ~ FelonyIndicator + PersonalCharge + ChargeClass + DrugCharge +
Gender + PropertyCharge + NumofMisdmr + Age +
NumofCaseCharge, data = trainData, family = "binomial")
summary(mylogit)
trainData$FTAProbability <- predict(mylogit, newdata = trainData, type = "response")
head(trainData)
install.packages('xlsReadWrite')
library(xlsReadWrite)
write.xls(trainData, "C:/Users/dkane/Documents/Consulting Projects/Marion County/ModelExport.xls")
library(xlsReadWrite)
library(xlsReadWrite)
install.packages('WriteXLS')
library(WriteXLS)
WriteXLS("trainData", "C:/Users/dkane/Documents/Consulting Projects/Marion County/ModelExport.xls")
install.packages('xlsx')
library(xlsx)
write.xlsx(trainData, "C:/Users/dkane/Documents/Consulting Projects/Marion County/ModelExport.xlsx", sheetName="Sheet1",
col.names=TRUE, row.names=TRUE, append=FALSE, showNA=TRUE)
births <- scan("http://robjhyndman.com/tsdldata/data/nybirths.dat")
birthstimeseries <- ts(births, frequency=12, start=c(1946,1))
birthstimeseries
births
birthstimeseries
plot.ts(birthstimeseries)
install.packages('TTR')
library("TTR")
birthstimeseriescomponents <- decompose(birthstimeseries)
birthstimeseriescomponents$seasonal
plot(birthstimeseriescomponents)
birthstimeseriescomponents <- decompose(birthstimeseries)
birthstimeseriesseasonallyadjusted <- birthstimeseries - birthstimeseriescomponents$seasonal
plot(birthstimeseriesseasonallyadjusted)
skirts <- scan("http://robjhyndman.com/tsdldata/roberts/skirts.dat",skip=5)
skirtsseries <- ts(skirts,start=c(1866))
plot.ts(skirtsseries)
skirtsseriesforecasts <- HoltWinters(skirtsseries, gamma=FALSE)
skirtsseriesforecasts
skirtsseriesforecasts
skirtsseriesforecasts$SSE
plot(skirtsseriesforecasts)
skirtsseriesforecasts2 <- HoltWinters(skirtsseries, gamma=FALSE, l.start=608, b.start=9)
plot(skirtsseriesforecasts2)
skirtsseriesforecasts2 <- forecast.HoltWinters(skirtsseriesforecasts, h=19)
plot.forecast(skirtsseriesforecasts2)
plot.forecast(skirtsseriesforecasts2)
Library("forecast")
library("forecast")
skirtsseriesforecasts2 <- forecast.HoltWinters(skirtsseriesforecasts, h=19)
plot.forecast(skirtsseriesforecasts2)
acf(skirtsseriesforecasts2$residuals, lag.max=20)
Box.test(skirtsseriesforecasts2$residuals, lag=20, type="Ljung-Box")
plot.ts(skirtsseriesforecasts2$residuals)
plotForecastErrors(skirtsseriesforecasts2$residuals)
plotForecastErrors <- function(forecasterrors)
{
# make a histogram of the forecast errors:
mybinsize <- IQR(forecasterrors)/4
mysd <- sd(forecasterrors)
mymin <- min(forecasterrors) - mysd*5
mymax <- max(forecasterrors) + mysd*3
# generate normally distributed data with mean 0 and standard deviation mysd
mynorm <- rnorm(10000, mean=0, sd=mysd)
mymin2 <- min(mynorm)
mymax2 <- max(mynorm)
if (mymin2 < mymin) { mymin <- mymin2 }
if (mymax2 > mymax) { mymax <- mymax2 }
# make a red histogram of the forecast errors, with the normally distributed data overlaid:
mybins <- seq(mymin, mymax, mybinsize)
hist(forecasterrors, col="red", freq=FALSE, breaks=mybins)
plotForecastErrors(skirtsseriesforecasts2$residuals)
plotForecastErrors <- function(forecasterrors)
{
# make a histogram of the forecast errors:
mybinsize <- IQR(forecasterrors)/4
mysd <- sd(forecasterrors)
mymin <- min(forecasterrors) - mysd*5
mymax <- max(forecasterrors) + mysd*3
# generate normally distributed data with mean 0 and standard deviation mysd
mynorm <- rnorm(10000, mean=0, sd=mysd)
mymin2 <- min(mynorm)
mymax2 <- max(mynorm)
if (mymin2 < mymin) { mymin <- mymin2 }
if (mymax2 > mymax) { mymax <- mymax2 }
# make a red histogram of the forecast errors, with the normally distributed data overlaid:
mybins <- seq(mymin, mymax, mybinsize)
hist(forecasterrors, col="red", freq=FALSE, breaks=mybins)
# freq=FALSE ensures the area under the histogram = 1
# generate normally distributed data with mean 0 and standard deviation mysd
myhist <- hist(mynorm, plot=FALSE, breaks=mybins)
# plot the normal curve as a blue line on top of the histogram of forecast errors:
points(myhist$mids, myhist$density, type="l", col="blue", lwd=2)
}
plotForecastErrors <- function(forecasterrors)
{
# make a histogram of the forecast errors:
mybinsize <- IQR(forecasterrors)/4
mysd <- sd(forecasterrors)
mymin <- min(forecasterrors) - mysd*5
mymax <- max(forecasterrors) + mysd*3
# generate normally distributed data with mean 0 and standard deviation mysd
mynorm <- rnorm(10000, mean=0, sd=mysd)
mymin2 <- min(mynorm)
mymax2 <- max(mynorm)
if (mymin2 < mymin) { mymin <- mymin2 }
if (mymax2 > mymax) { mymax <- mymax2 }
# make a red histogram of the forecast errors, with the normally distributed data overlaid:
mybins <- seq(mymin, mymax, mybinsize)
hist(forecasterrors, col="red", freq=FALSE, breaks=mybins)
# freq=FALSE ensures the area under the histogram = 1
# generate normally distributed data with mean 0 and standard deviation mysd
myhist <- hist(mynorm, plot=FALSE, breaks=mybins)
# plot the normal curve as a blue line on top of the histogram of forecast errors:
points(myhist$mids, myhist$density, type="l", col="blue", lwd=2)
}
plotForecastErrors(skirtsseriesforecasts2$residuals)
library("TTR")
skirts <- scan("http://robjhyndman.com/tsdldata/roberts/skirts.dat",skip=5)
skirtsseries <- ts(skirts,start=c(1866))
plot.ts(skirtsseries)
skirtsseriesforecasts <- HoltWinters(skirtsseries, gamma=FALSE)
skirtsseriesforecasts
skirtsseriesforecasts$SSE
plot(skirtsseriesforecasts)
skirtsseriesforecasts2 <- HoltWinters(skirtsseries, gamma=FALSE, l.start=608, b.start=9)
plot(skirtsseriesforecasts2)
plotForecastErrors <- function(forecasterrors)
{
# make a histogram of the forecast errors:
mybinsize <- IQR(forecasterrors)/4
mysd <- sd(forecasterrors)
mymin <- min(forecasterrors) - mysd*5
mymax <- max(forecasterrors) + mysd*3
# generate normally distributed data with mean 0 and standard deviation mysd
mynorm <- rnorm(10000, mean=0, sd=mysd)
mymin2 <- min(mynorm)
mymax2 <- max(mynorm)
if (mymin2 < mymin) { mymin <- mymin2 }
if (mymax2 > mymax) { mymax <- mymax2 }
# make a red histogram of the forecast errors, with the normally distributed data overlaid:
mybins <- seq(mymin, mymax, mybinsize)
hist(forecasterrors, col="red", freq=FALSE, breaks=mybins)
# freq=FALSE ensures the area under the histogram = 1
# generate normally distributed data with mean 0 and standard deviation mysd
myhist <- hist(mynorm, plot=FALSE, breaks=mybins)
# plot the normal curve as a blue line on top of the histogram of forecast errors:
points(myhist$mids, myhist$density, type="l", col="blue", lwd=2)
}
library("forecast")
skirtsseriesforecasts2 <- forecast.HoltWinters(skirtsseriesforecasts, h=19)
plot.forecast(skirtsseriesforecasts2)
acf(skirtsseriesforecasts2$residuals, lag.max=20)
Box.test(skirtsseriesforecasts2$residuals, lag=20, type="Ljung-Box")
plot.ts(skirtsseriesforecasts2$residuals)
plotForecastErrors(skirtsseriesforecasts2$residuals)
library(car)
setwd("C:/Users/kane.de/Documents/RPackages/Regression Tutorial")
reg1 <- lm(prestige ~ education + log2(income) + women, data=Prestige)
summary(reg1)
prestige_hat<-fitted(reg1) # predicted values
as.data.frame(prestige_hat)
reg2 <- lm(prestige ~ education + log2(income) + type, data=Prestige)
summary(reg2)
Prestige$type<-with(Prestige, factor(type, levels=c("bc", "wc", "prof")))
reg3 <- lm(prestige ~ type*(education + log2(income)), data=Prestige)
summary(reg3)
residualPlots(reg1)
residualPlots(reg1, ~ 1, fitted=TRUE) #Residuals vs fitted only
residualPlots(reg1, ~ education, fitted=FALSE) # Residuals vs education only
reg4 <-lm(prestige ~ education + income + type, data = Prestige)
influenceIndexPlot(reg1, id.n=3)
qqPlot(reg4)
ncvTest(reg4)
vif(reg4)
reg4 <-lm(prestige ~ education + income + type, data = Prestige)
trainData$Prestige2 <- predict(reg4, newdata = trainData, type = "response")
trainData$Prestige2 <- predict(reg4, newdata = data type = "response")
trainData$Prestige2 <- predict(reg4, newdata = data, type = "response")
trainData$Prestige2 <- predict(reg4, newdata = Prestige, type = "response")
Prestige$Prestige2 <- predict(reg4, newdata = Prestige, type = "response")
Prestige
reg4 <-lm(prestige ~ education + income + type, data = Prestige)
summary(reg4)
library(xlsx)
write.xlsx(Prestige, "C:/Users/dkane/Documents/Consulting Projects/ModelExport.xlsx", sheetName="Sheet1",
col.names=TRUE, row.names=TRUE, append=FALSE, showNA=TRUE)
install.packages('neuralnet')
library("neuralnet")
traininginput <-  as.data.frame(runif(50, min=0, max=100))
trainingoutput <- sqrt(traininginput)
trainingdata <- cbind(traininginput,trainingoutput)
colnames(trainingdata) <- c("Input","Output")
Summary(trainingdata)
summary(trainingdata)
head(trainingdata)
net.sqrt <- neuralnet(Output~Input,trainingdata, hidden=10, threshold=0.01)
print(net.sqrt)
plot(net.sqrt)
testdata <- as.data.frame((1:10)^2) #Generate some squared numbers
net.results <- compute(net.sqrt, testdata) #Run them through the neural network
ls(net.results)
print(net.results$net.result)
cleanoutput <- cbind(testdata,sqrt(testdata),
as.data.frame(net.results$net.result))
colnames(cleanoutput) <- c("Input","Expected Output","Neural Net Output")
print(cleanoutput)
net.sqrt <- neuralnet(Output~Input,trainingdata, hidden=5, threshold=0.01)
print(net.sqrt)
print(net.sqrt)
plot(net.sqrt)
install.packages("Caret")
install.packages("caret")
mydata<- read.csv("C:/Users/dkane/Documents/R Packages/Marion County/recidivism4e2.csv")
attach(mydata)
library(aod)
library(ggplot2)
library(reshape2)
library(car)
library(corrplot)
library(caret)
set.seed(1234)
ind <- sample(2, nrow(mydata), replace=TRUE, prob=c(0.7, 0.3))
trainData <- mydata[ind==1,]
testData <- mydata[ind==2,]
mydata<- read.csv("C:/Users/dkane/Documents/R Packages/Marion County/recidivism4e2.csv")
attach(mydata)
library(aod)
library(ggplot2)
library(reshape2)
library(car)
library(corrplot)
library(caret)
set.seed(1234)
ind <- sample(2, nrow(mydata), replace=TRUE, prob=c(0.7, 0.3))
trainData <- mydata[ind==1,]
testData <- mydata[ind==2,]
mylogit <- glm(FTA ~ FelonyIndicator + PersonalCharge + ChargeClass + DrugCharge +
Gender + PropertyCharge + NumofMisdmr + Age +
NumofCaseCharge, data = trainData, family = "binomial")
summary(mylogit)
library(ROCR)
pred1 <- prediction(fitted(mylogit), trainData$FTA)
stats1 <- performance(pred1 ,'tpr', 'tnr')
# stats1@alpha.values[[1]]
# If the first value is infinite, we need to change this to a 1
# the code below will make this change.
stats1@alpha.values[[1]][1] <- 1
# This code plots specificity and sensitivity against the cutoffs.
# The MDT and MST are different measures for performance. We must choose one.
plot(stats1@alpha.values[[1]], stats1@x.values[[1]], xlab=stats1@alpha.name, ylab='Classification rate', type='s')
lines(stats1@alpha.values[[1]], stats1@y.values[[1]], type='s', col=2)
legend('right', c('specificity', 'sensitivity', 'MDT', 'MST'), col=c(1,2,4,'seagreen'), lty=c(1,1,2,3), lwd=c(1,1,1,2), bty='n', cex=.9)
precision<-function(c) {
tab1 <- table(fitted(mylogit)>c, trainData$FTA)
out <- diag(tab1)/apply(tab1, 2, sum)
names(out) <- c('specificity', 'sensitivity')
list(tab1, out)
}
precision(.5)
library(ROCR)
pred1 <- prediction(fitted(mylogit), trainData$FTA)
stats1 <- performance(pred1 ,'tpr', 'tnr')
# stats1@alpha.values[[1]]
# If the first value is infinite, we need to change this to a 1
# the code below will make this change.
stats1@alpha.values[[1]][1] <- 1
# This is how we can create an ROC Curve using ROCR.
stats1<-performance(pred1,'tpr','fpr')
plot(stats1@x.values[[1]],stats1@y.values[[1]],type='s',ylab=stats1@y.name,xlab=stats1@x.name, col="Blue", main="ROC Chart")
abline(0,1,col="Red")
#Calculate area under the curve. This is showing a value of 0.638
stats1<-performance(pred1,'auc')
str(stats1)
library(ROCR)
pred2 <- prediction(fitted(mylogit), testData$FTA)
stats2 <- performance(pred2 ,'tpr', 'tnr')
# stats1@alpha.values[[1]]
# If the first value is infinite, we need to change this to a 1
# the code below will make this change.
stats2@alpha.values[[1]][1] <- 1
# This is how we can create an ROC Curve using ROCR.
stats2<-performance(pred2,'tpr','fpr')
plot(stats1@x.values[[1]],stats1@y.values[[1]],type='s',ylab=stats1@y.name,xlab=stats1@x.name, col="Blue", main="ROC Chart")
abline(0,1,col="Red")
#Calculate area under the curve. This is showing a value of 0.638
stats2<-performance(pred2,'auc')
str(stats2)
pred2 <- prediction(fitted(mylogit), testData$FTA)
library(ROCR)
pred1 <- prediction(fitted(mylogit), trainData$FTA)
stats1 <- performance(pred1 ,'tpr', 'fpr')
stats1@alpha.values[[1]][1] <- 1
stats1<-performance(pred1,'tpr','fpr')
plot(stats1@x.values[[1]],stats1@y.values[[1]],type='s',ylab=stats1@y.name,xlab=stats1@x.name, col="Blue", main="ROC Chart")
abline(0,1,col="Red")
#Calculate area under the curve. This is showing a value of 0.638
stats1<-performance(pred1,'auc')
str(stats1)
set.seed(123)
# Set the working directory for the analysis.
setwd("C:/Users/dkane/Documents/R Packages/Marion County")
# Import the data from csv file
mydata<- read.csv("C:/Users/dkane/Documents/R Packages/Marion County/recidivism4e2.csv")
attach(mydata)
set.seed(1234)
ind <- sample(2, nrow(mydata), replace=TRUE, prob=c(0.7, 0.3))
trainData <- mydata[ind==1,]
testData <- mydata[ind==2,]
mylogit <- glm(FTA ~ FelonyIndicator + PersonalCharge + ChargeClass + DrugCharge +
Gender + PropertyCharge + NumofMisdmr + Age +
NumofCaseCharge, data = trainData, family = "binomial")
save(mylogit, file = "my_model1.rda")
setwd("C:/Users/dkane/Documents/R Packages/Automation Example")
save(mylogit, file = "my_model1.rda")
setwd("C:/Users/dkane/Documents/R Packages/Marion County")
# Import the data from csv file
mydata<- read.csv("C:/Users/dkane/Documents/R Packages/Marion County/recidivism4e2.csv")
attach(mydata)
setwd("C:/Users/dkane/Documents/R Packages/Automation Example")
load("my_model1.rda")
mydata$FTAProbability <- predict(mylogit, newdata = mydata, type = "response")
View(mydata)
mydata<-iris
View(mydata)
library(randomForest)
RandomForestModel <- randomForest(Species ~ Sepal.Width + Sepal.Length + Petal.Length + Petal.Width, data=mydata, ntree=500, mtry=5, importance=TRUE)
print(RandomForestModel)
importance(RandomForestModel)
plot.new()
plot(RandomForestModel, log="y")
varImpPlot(RandomForestModel)
plot.new()
varImpPlot(RandomForestModel, type=1, pch=19, col=1, cex=1.0, main="")
abline(v=9, col="blue")
varImpPlot(RandomForestModel, type=2, pch=19, col=1, cex=1.0, main="")
mydata$RFPredict <- predict(RandomForestModel, newdata = mydata, type = "response")
View(mydata)
set.seed(123)
RandomForestModel <- randomForest(Species ~ Sepal.Width + Sepal.Length + Petal.Length + Petal.Width, data=mydata, ntree=500, mtry=5, importance=TRUE)
mydata<-iris
library(randomForest)
set.seed(123)
RandomForestModel <- randomForest(Species ~ Sepal.Width + Sepal.Length + Petal.Length + Petal.Width, data=mydata, ntree=500, mtry=5, importance=TRUE)
print(RandomForestModel)
importance(RandomForestModel)
mydata$RFPredict <- predict(RandomForestModel, newdata = mydata, type = "response")
View(mydata)
View(mydata)
mydata<-iris
library(randomForest)
set.seed(123)
RandomForestModel <- randomForest(Species ~ Sepal.Width + Sepal.Length + Petal.Length + Petal.Width, data=mydata, ntree=2, mtry=5, importance=TRUE)
library(randomForest)
set.seed(123)
RandomForestModel <- randomForest(Species ~ Sepal.Width + Sepal.Length + Petal.Length + Petal.Width, data=mydata, ntree=5, mtry=5, importance=TRUE)
library(randomForest)
set.seed(123)
RandomForestModel <- randomForest(Species ~ Sepal.Width + Sepal.Length + Petal.Length + Petal.Width, data=mydata, ntree=5, mtry=4, importance=TRUE)
mydata$RFPredict <- predict(RandomForestModel, newdata = mydata, type = "response")
View(mydata)
mydata<-iris
library(randomForest)
set.seed(123)
RandomForestModel <- randomForest(Species ~ Sepal.Width + Sepal.Length + Petal.Length + Petal.Width, data=mydata, ntree=5, mtry=4, importance=TRUE)
print(RandomForestModel)
importance(RandomForestModel)
library(randomForest)
set.seed(123)
RandomForestModel <- randomForest(Species ~ Sepal.Width + Sepal.Length + Petal.Length + Petal.Width, data=mydata, ntree=500, mtry=4, importance=TRUE)
print(RandomForestModel)
importance(RandomForestModel)
mydata$RFPredict <- predict(RandomForestModel, newdata = mydata, type = "response")
View(mydata)
mydata<-iris
library(randomForest)
set.seed(123)
RandomForestModel <- randomForest(Species ~ Sepal.Width + Sepal.Length + Petal.Length + Petal.Width, data=mydata, ntree=500, mtry=4, importance=TRUE)
print(RandomForestModel)
mydata$RFPredict <- predict(RandomForestModel, newdata = mydata, type = "response")
View(mydata)
mydata<-iris
library(randomForest)
set.seed(124)
RandomForestModel <- randomForest(Species ~ Sepal.Width + Sepal.Length + Petal.Length + Petal.Width, data=mydata, ntree=5, mtry=4, importance=TRUE)
print(RandomForestModel)
mydata$RFPredict <- predict(RandomForestModel, newdata = mydata, type = "response")
View(mydata)
mydata<-iris
library(randomForest)
set.seed(124)
RandomForestModel <- randomForest(Species ~ Sepal.Width + Sepal.Length + Petal.Length + Petal.Width, data=mydata, ntree=1, mtry=4, importance=TRUE)
print(RandomForestModel)
mydata$RFPredict <- predict(RandomForestModel, newdata = mydata, type = "response")
View(mydata)
mydata$RFProb <- predict(RandomForestModel, newdata = mydata, type = "prob")
View(mydata)
mydata$RFClass <- predict(RandomForestModel, newdata = mydata, type = "class")
View(mydata)
