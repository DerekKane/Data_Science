install.packages('wordcloud')
install.packages('SnowballC')
install.packages('GGally')
install.packages('car')
install.packages('corrplot')
install.packages('languageR')
install.packages('Design')
install.packages('TTR')
install.packages('rattle')
install.packages('arules')
install.packages('doParallel')
install.packages('foreach')
install.packages('foreign')
install.packages('gclus')
install.packages('lattice')
install.packages('MASS')
install.packages('nnet')
install.packages('parallel')
install.packages('pROC')
install.packages('Rfacebook')
install.packages('RgoogleMaps')
install.packages('ROCR')
install.packages('survival')
install.packages('quantmod')
install.packages('h2o')
install.packages('glmnet')
install.packages('car')
install.packages("TTR")
install.packages("lattice")
install.packages("MASS")
install.packages("quantmod")
install.packages("quantmod")
sum(hm_model$HMM$transMat[last(VitPath$states),]*.colSums((matrix(unlist(hm_model$HMM$distribution$mean),nrow=4,ncol=5)))*(matrix(unlist(hm_model$HMM$distribution$proportion),nrow=4,ncol=5)),m=4,n=5)
hm_model <- HMMFit(obs=TWII_Train, dis="MIXTURE", nStates=5, nMixt=4)
value <- sum(hm_model$HMM$transMat[last(VitPath$states),]*.colSums((matrix(unlist(hm_model$HMM$distribution$mean),nrow=4,ncol=5)))*(matrix(unlist(hm_model$HMM$distribution$proportion),nrow=4,ncol=5)),m=4,n=5)
library(quantmod)
getSymbols("FB", src = "yahoo", from = "1900-01-01", to = "2014-04-01")
View(FB)
chartSeries(FB, theme="black")
TWII_Subset <- window(FB, start=as.Date("2012-01-01"), end = as.Date("2013-04-01"))
TWII_Train <- cbind(TWII_Subset$TWII.Close - TWII_Subset$TWII.Open,
TWII_Subset$TWII.Volume)
View(TWII_Train)
View(FB)
TWII_Subset <- window(FB, start=as.Date("2013-01-01"), end = as.Date("2014-04-01"))
TWII_Train <- cbind(TWII_Subset$TWII.Close - TWII_Subset$TWII.Open,
TWII_Subset$TWII.Volume)
View(TWII_Subset)
TWII_Train <- cbind(TWII_Subset$FB.Close - TWII_Subset$FB.Open,
TWII_Subset$FB.Volume)
library(RHmm)
hm_model <- HMMFit(obs=TWII_Train, dis="MIXTURE", nStates=5, nMixt=4)
print(hm_model)
TWII_Train <- cbind(TWII_Subset$FB.Close - TWII_Subset$FB.Open)
View(TWII_Train)
TWII_Train <- cbind(TWII_Subset$FB.Close - TWII_Subset$FB.Open)
hm_model <- HMMFit(obs=TWII_Train, dis="MIXTURE", nStates=5, nMixt=4)
print(hm_model)
VitPath <- viterbi(hm_model, TWII_Train)
last(VitPath$states)
value <- sum(hm_model$HMM$transMat[last(VitPath$states),]*.colSums((matrix(unlist(hm_model$HMM$distribution$mean),nrow=4,ncol=5)))*(matrix(unlist(hm_model$HMM$distribution$proportion),nrow=4,ncol=5)),m=4,n=5)
sum(hm_model$HMM$transMat[last(VitPath$states),]*.colSums((matrix(unlist(hm_model$HMM$distribution$mean),nrow=4,ncol=5)))*(matrix(unlist(hm_model$HMM$distribution$proportion),nrow=4,ncol=5)),m=4,n=5)
m = nMixt, n = nStates
print(hm_model$HMM$transMat[last(VitPath$states),])
print(hm_model$HMM$distribution$mean[, seq(1, ncol(hm_model$HMM$distribution$mean), by = 2)])
print(unlist(hm_model$HMM$distribution$mean))
print(matrix(unlist(hm_model$HMM$distribution$proportion[1,])))
change <- sum(hm_model$HMM$transMat[last(VitPath$states),] * .colSums((matrix(unlist(hm_model$HMM$distribution$mean),nrow=4,ncol=5)) * (matrix(unlist(hm_model$HMM$distribution$proportion), nrow=4,ncol=5)), m=4,n=5))
View(TWII_Train)
View(TWII_Train)
View(TWII_Subset)
View(TWII_Subset)
View(TWII_Subset)
predict <- TWII_Subset$FB.Open[TWII_Subset$row.names == "2014-04-01"]
View(predict)
TWII_Subset$FB.Open
mydata <- my_xts["2014-04-01"]
mydata <- TWII_Subset["2014-04-01"]
View(mydata)
mydata <- last(TWII_Subset)
library(quantmod)
getSymbols("FB", src = "yahoo", from = "1900-01-01", to = "2014-04-01")
chartSeries(FB, theme="black")
library(quantmod)
getSymbols("FB", src = "yahoo", from = "1900-01-01", to = "2014-04-01")
chartSeries(FB, theme="black")
FB_Subset <- window(FB, start=as.Date("2013-01-01"), end = as.Date("2014-04-01"))
FB_Train <- cbind(FB_Subset$FB.Close - FB_Subset$FB.Open)
library(RHmm)
hm_model <- HMMFit(obs=FB_Train, dis="MIXTURE", nStates=5, nMixt=4)
print(hm_model)
hm_model <- HMMFit(obs=FB_Train, dis="MIXTURE", nStates=5, nMixt=4, control=list(iter=2000))
TWII_Subset$FB.Open
print(hm_model)
VitPath <- viterbi(hm_model, FB_Train)
FB_Predict <- cbind(FB_Subset$FB.Close, VitPath$states)
chartSeries(FB_Predict[,1])
addTA(FB_Predict[FB_Predict[,2]==1,1],on=1,type="p",col=5,pch=25)
addTA(FB_Predict[FB_Predict[,2]==2,1],on=1,type="p",col=6,pch=24)
addTA(FB_Predict[FB_Predict[,2]==3,1],on=1,type="p",col=7,pch=23)
addTA(FB_Predict[FB_Predict[,2]==4,1],on=1,type="p",col=8,pch=22)
addTA(FB_Predict[FB_Predict[,2]==5,1],on=1,type="p",col=10,pch=21)
change <- sum(hm_model$HMM$transMat[last(VitPath$states),] * .colSums((matrix(unlist(hm_model$HMM$distribution$mean),nrow=4,ncol=5)) * (matrix(unlist(hm_model$HMM$distribution$proportion), nrow=4,ncol=5)), m=4,n=5))
mydata <- last(FB_Subset)
View(mydata)
predict <- mydata$FB.Open + change
View(predict)
View(mydata)
predict$FB.Open <- mydata$FB.Open + change
View(predict)
predict$FB.Open
require(devEMF)
require(devEMF)
install.packages('devEMF')
require(devEMF)
library(quantmod)
library(RHmm)
library(parallel)
getSymbols("FB", src = "yahoo", from = "1900-01-01", to = "2014-04-01")
print(head(FB))
print(tail(FB))
chartSeries(FB, theme="white")
trainsetraw <- window(FB, start = as.Date("1900-01-01"), end = as.Date("2013-04-01"))
print(ncol(trainsetraw)-1)
print(trainsetraw[,1:ncol(trainsetraw)-1])
trainset <- na.omit(trainsetraw[,1:ncol(trainsetraw)-1])
View(trainset)
print(trainset)
train <- cbind(trainset$FB.Close - trainset$FB.Open)
testset <- window(FB, start = as.Date("2013-04-02"), end = as.Date("2014-04-01"))
test <- cbind(testset$FB.Close - testset$FB.Open)
print(testset)
hm_model <- HMMFit(obs = train, nStates = 5, nMixt = 4, dis = "MIXTURE")
print(hm_model)
hm_model <- HMMFit(obs = train, nStates = 5, nMixt = 4, dis = "MIXTURE", control=list(iter=2000))
print(hm_model)
hm_model <- HMMFit(obs = train, nStates = 5, nMixt = 4, dis = "MIXTURE", control=list(iter=2000))
print(hm_model)
require(devEMF)
library(quantmod)
library(RHmm)
library(parallel)
#png('FB.png')
getSymbols("FB", src = "yahoo", from = "1900-01-01", to = "2014-04-01")
#getSymbols("FB", src = "google")
#getSymbols("FB")
print(head(FB))
print(tail(FB))
chartSeries(FB, theme="white")
#trainset <- window(FB, start = as.Date("1900-01-01"), end = as.Date("2013-04-01"))
trainsetraw <- window(FB, start = as.Date("1900-01-01"), end = as.Date("2013-04-01"))
print(ncol(trainsetraw)-1)
print(trainsetraw[,1:ncol(trainsetraw)-1])
trainset <- na.omit(trainsetraw[,1:ncol(trainsetraw)-1])
print(trainset)
#FB_Subset <- window(FB, start = as.Date("1900-01-01"), end = as.Date("2013-04-01"))
#FB_Train <- cbind(FB_Subset$FB.Close - FB_Subset$FB.Open, FB_Subset$FB.Volume)
train <- cbind(trainset$FB.Close - trainset$FB.Open)
#print(train)
testset <- window(FB, start = as.Date("2013-04-02"), end = as.Date("2014-04-01"))
test <- cbind(testset$FB.Close - testset$FB.Open)
print(testset)
# Baum-Welch Algorithm to find the model for the given observations
#hm_model <- HMMFit(obs = FB_Train, nStates = 5)
hm_model <- HMMFit(obs = train, nStates = 5, nMixt = 4, dis = "MIXTURE", control=list(iter=2000))
print(hm_model)
VitPath <- viterbi (hm_model, train)
print(VitPath)
png('FB.png')
FB_Predict <- cbind(trainset$FB.Close, VitPath$states)
testset <- cbind(testset, Pred = 0)
rows = nrow(testset)
rows
MAPEsum = 0
NRMSEsum = 0
for (i in 1: rows) {
#if (i == rows) break
if(i != 0) {
testrow <- testset[i, ]
#print(testrow)
todayopen <- testset$FB.Open[i, ]
actual <- testset$FB.Close[i, ]
#todayclose <- testset$FB.Close[i, ]
}
change <- sum(hm_model$HMM$transMat[last(VitPath$states),] * .colSums((matrix(unlist(hm_model$HMM$distribution$mean), nrow=4,ncol=5)) * (matrix(unlist(hm_model$HMM$distribution$proportion), nrow=4,ncol=5)), m=4,n=5))
print(change)
pred <- todayopen + change
testset[i, ]$Pred <- pred
print(testset[i, ])
diff = (abs ((pred - actual)/ actual))[1,]$FB.Open
MAPEsum <- sum(MAPEsum, diff[1,1])
NRMSEsum <- sum(NRMSEsum, (pred - actual)^2)
train <- rbind (train, todayclose - todayopen)
hm_model <- HMMFit(obs = train, nStates = 5, nMixt = 4, dis = "MIXTURE")
VitPath <- viterbi (hm_model, train)
}
print(paste0("[Stat] Rows = ", rows))
MAPE <- MAPEsum*100/rows
print(paste0("[Stat] MAPEsum = ", MAPEsum))
print(paste0("[Stat] MAPE = ", MAPE))
actuals <- testset$FB.Close
ymax = max (actuals)
ymin = min (actuals)
source('~/.active-rstudio-document', echo=TRUE)
NRMSE <- sqrt(NRMSEsum)/(rows * (ymax - ymin))
print(paste0("[Stat] NRMSE = ", NRMSE))
chartSeries(testset[1:rows, 1], theme= chartTheme('white', up.col = 'blue'), name = "FB", legend = "Actual",
TA = "addTA(testset[1:rows, ncol(testset)], on = 1, col='red')")
postscript('FB.eps')
chartSeries(testset[1:rows, 1], theme= chartTheme('white', up.col = 'blue'), name = "FB", legend = "Actual",
TA = "addTA(testset[1:rows, ncol(testset)], on = 1, col='red')")
library(quantmod)
getSymbols("FB", src = "yahoo", from = "1900-01-01", to = "2014-04-01")
chartSeries(FB, theme="black")
View(FB)
library(quantmod)
getSymbols("FB", src = "yahoo", from = "1900-01-01", to = "2015-12-31")
chartSeries(FB, theme="black")
library(quantmod)
getSymbols("FB", src = "yahoo", from = "1900-01-01", to = "2015-12-31")
chartSeries(FB, theme="black")
FB_Subset <- window(FB, start=as.Date("2013-01-01"), end = as.Date("2015-12-31"))
FB_Train <- cbind(FB_Subset$FB.Close - FB_Subset$FB.Open)
library(RHmm)
hm_model <- HMMFit(obs=FB_Train, dis="MIXTURE", nStates=5, nMixt=4, control=list(iter=2000))
print(hm_model)
VitPath <- viterbi(hm_model, FB_Train)
FB_Predict <- cbind(FB_Subset$FB.Close, VitPath$states)
chartSeries(FB_Predict[,1])
addTA(FB_Predict[FB_Predict[,2]==1,1],on=1,type="p",col=5,pch=25)
addTA(FB_Predict[FB_Predict[,2]==2,1],on=1,type="p",col=6,pch=24)
addTA(FB_Predict[FB_Predict[,2]==3,1],on=1,type="p",col=7,pch=23)
addTA(FB_Predict[FB_Predict[,2]==4,1],on=1,type="p",col=8,pch=22)
addTA(FB_Predict[FB_Predict[,2]==5,1],on=1,type="p",col=10,pch=21)
change <- sum(hm_model$HMM$transMat[last(VitPath$states),] * .colSums((matrix(unlist(hm_model$HMM$distribution$mean),nrow=4,ncol=5)) * (matrix(unlist(hm_model$HMM$distribution$proportion), nrow=4,ncol=5)), m=4,n=5))
mydata <- last(FB_Subset)
predict <- mydata$FB.Open + change
predict$FB.Open
getSymbols("GEA", src = "yahoo", from = "1900-01-01", to = "2015-12-31")
getSymbols("apple", src = "yahoo", from = "1900-01-01", to = "2015-12-31")
getSymbols("GOOG", src = "yahoo", from = "1900-01-01", to = "2015-12-31")
chartSeries(GOOG, theme="black")
GOOG_Subset <- window(GOOG, start=as.Date("2013-01-01"), end = as.Date("2015-12-31"))
GOOG_Train <- cbind(GOOG_Subset$GOOG.Close - GOOG_Subset$GOOG.Open)
library(RHmm)
hm_model <- HMMFit(obs=GOOG_Train, dis="MIXTURE", nStates=5, nMixt=4, control=list(iter=2000))
print(hm_model)
VitPath <- viterbi(hm_model, GOOG_Train)
GOOG_Predict <- cbind(GOOG_Subset$GOOG.Close, VitPath$states)
chartSeries(GOOG_Predict[,1])
addTA(GOOG_Predict[GOOG_Predict[,2]==1,1],on=1,type="p",col=5,pch=25)
addTA(GOOG_Predict[GOOG_Predict[,2]==2,1],on=1,type="p",col=6,pch=24)
addTA(GOOG_Predict[GOOG_Predict[,2]==3,1],on=1,type="p",col=7,pch=23)
addTA(GOOG_Predict[GOOG_Predict[,2]==4,1],on=1,type="p",col=8,pch=22)
addTA(GOOG_Predict[GOOG_Predict[,2]==5,1],on=1,type="p",col=10,pch=21)
getSymbols("TWII", src = "yahoo", from = "1900-01-01", to = "2015-12-31")
getSymbols("^TWII", src = "yahoo", from = "1900-01-01", to = "2015-12-31")
chartSeries(TWII, theme="black")
TWII_Subset <- window(TWII, start=as.Date("2013-01-01"), end = as.Date("2015-12-31"))
TWII_Train <- cbind(TWII_Subset$TWII.Close - TWII_Subset$TWII.Open)
library(RHmm)
hm_model <- HMMFit(obs=TWII_Train, dis="MIXTURE", nStates=5, nMixt=4, control=list(iter=2000))
print(hm_model)
VitPath <- viterbi(hm_model, TWII_Train)
TWII_Predict <- cbind(TWII_Subset$TWII.Close, VitPath$states)
chartSeries(TWII_Predict[,1])
addTA(TWII_Predict[TWII_Predict[,2]==1,1],on=1,type="p",col=5,pch=25)
addTA(TWII_Predict[TWII_Predict[,2]==2,1],on=1,type="p",col=6,pch=24)
addTA(TWII_Predict[TWII_Predict[,2]==3,1],on=1,type="p",col=7,pch=23)
addTA(TWII_Predict[TWII_Predict[,2]==4,1],on=1,type="p",col=8,pch=22)
addTA(TWII_Predict[TWII_Predict[,2]==5,1],on=1,type="p",col=10,pch=21)
change <- sum(hm_model$HMM$transMat[last(VitPath$states),] * .colSums((matrix(unlist(hm_model$HMM$distribution$mean),nrow=4,ncol=5)) * (matrix(unlist(hm_model$HMM$distribution$proportion), nrow=4,ncol=5)), m=4,n=5))
mydata <- last(TWII_Subset)
predict <- mydata$TWII.Open + change
predict$TWII.Open
View(mydata)
library(quantmod)
getSymbols("^TWII", src = "yahoo", from = "1900-01-01", to = "2015-12-31")
chartSeries(TWII, theme="black")
View(TWII)
write.csv(TWII, file='C:/Users/Derek/Documents/mydata.csv', row.names=F)
TWII_Subset <- window(TWII, start=as.Date("2013-01-01"), end = as.Date("2015-12-31"))
TWII_Train <- cbind(TWII_Subset$TWII.Close - TWII_Subset$TWII.Open)
library(RHmm)
# hm_model <- HMMFit(obs=TWII_Train, nStates=5)
hm_model <- HMMFit(obs=TWII_Train, nStates=5)
print(hm_model)
library(quantmod)
getSymbols("^TWII", src = "yahoo", from = "1900-01-01", to = "2015-12-31")
chartSeries(TWII, theme="black")
TWII_Subset <- window(TWII, start=as.Date("2013-01-01"), end = as.Date("2015-12-31"))
TWII_Train <- cbind(TWII_Subset$TWII.Close - TWII_Subset$TWII.Open)
library(RHmm)
# Baum-Welch Algorithm
# hm_model <- HMMFit(obs=TWII_Train, nStates=5)
hm_model <- HMMFit(obs=TWII_Train, dis="MIXTURE", nStates=5, nMixt=4, control=list(iter=2000))
print(hm_model)
library(quantmod)
getSymbols("^TWII", src = "yahoo", from = "1900-01-01", to = "2015-12-31")
chartSeries(TWII, theme="black")
TWII_Subset <- window(TWII, start=as.Date("2013-01-01"), end = as.Date("2015-12-31"))
TWII_Train <- cbind(TWII_Subset$TWII.Close - TWII_Subset$TWII.Open)
library(RHmm)
hm_model <- HMMFit(obs=TWII_Train, nStates=5)
print(hm_model)
change <- sum(hm_model$HMM$transMat[last(VitPath$states),] * .colSums((matrix(unlist(hm_model$HMM$distribution$mean),nrow=2,ncol=5)) * (matrix(unlist(hm_model$HMM$distribution$proportion), nrow=2,ncol=5)), m=2,n=5))
VitPath <- viterbi(hm_model, TWII_Train)
change <- sum(hm_model$HMM$transMat[last(VitPath$states),] * .colSums((matrix(unlist(hm_model$HMM$distribution$mean),nrow=2,ncol=5)) * (matrix(unlist(hm_model$HMM$distribution$proportion), nrow=2,ncol=5)), m=2,n=5))
#################################################################################
# Hidden Markov Model Example
#################################################################################
# http://www.slideshare.net/ChiuYW/hidden-markov-model-stock-prediction
# https://github.com/david78k/stock/blob/master/rhmm/TWII.R
# http://stackoverflow.com/questions/11644522/getting-the-next-observation-from-a-hmm-gaussian-mixture-distribution
# install.packages("quantmod")
library(quantmod)
getSymbols("^TWII", src = "yahoo", from = "1900-01-01", to = "2015-12-31")
chartSeries(TWII, theme="black")
TWII_Subset <- window(TWII, start=as.Date("2013-01-01"), end = as.Date("2015-12-31"))
TWII_Train <- cbind(TWII_Subset$TWII.Close - TWII_Subset$TWII.Open)
# TWII_Train <- cbind(TWII_Subset$TWII.Close - TWII_Subset$TWII.Open,
#                  TWII_Subset$TWII.Volume)
#################################################################################
# Baum-Welch Algorithm
#################################################################################
library(RHmm)
# Package Located at https://r-forge.r-project.org/R/?group_id=85
# hm_model <- HMMFit(obs=TWII_Train, nStates=5)
hm_model <- HMMFit(obs=TWII_Train, dis="MIXTURE", nStates=5, nMixt=4,
control=list(iter=2000))
print(hm_model)
#################################################################################
# Hidden Markov Model Example
#################################################################################
# http://www.slideshare.net/ChiuYW/hidden-markov-model-stock-prediction
# https://github.com/david78k/stock/blob/master/rhmm/TWII.R
# http://stackoverflow.com/questions/11644522/getting-the-next-observation-from-a-hmm-gaussian-mixture-distribution
# install.packages("quantmod")
library(quantmod)
getSymbols("^TWII", src = "yahoo", from = "1900-01-01", to = "2015-12-31")
chartSeries(TWII, theme="black")
TWII_Subset <- window(TWII, start=as.Date("2013-01-01"), end = as.Date("2015-12-31"))
TWII_Train <- cbind(TWII_Subset$TWII.Close - TWII_Subset$TWII.Open)
# TWII_Train <- cbind(TWII_Subset$TWII.Close - TWII_Subset$TWII.Open,
#                  TWII_Subset$TWII.Volume)
#################################################################################
# Baum-Welch Algorithm
#################################################################################
library(RHmm)
# Package Located at https://r-forge.r-project.org/R/?group_id=85
# hm_model <- HMMFit(obs=TWII_Train, nStates=5)
hm_model <- HMMFit(obs=TWII_Train, dis="MIXTURE", nStates=5, nMixt=4,control=list(iter=2000))
print(hm_model)
View(TWII_Train)
VitPath <- viterbi(hm_model, TWII_Train)
VitPath
hm_model
VitPath <- viterbi(hm_model, TWII_Train)
#################################################################################
# Predict the known values of the HMM model
#################################################################################
TWII_Predict <- cbind(TWII_Subset$TWII.Close, VitPath$states)
View(TWII_Predict)
View(TWII_Predict)
chartSeries(TWII_Predict[,1])
addTA(TWII_Predict[TWII_Predict[,2]==1,1],on=1,type="p",col=5,pch=25)
addTA(TWII_Predict[TWII_Predict[,2]==2,1],on=1,type="p",col=6,pch=24)
addTA(TWII_Predict[TWII_Predict[,2]==3,1],on=1,type="p",col=7,pch=23)
addTA(TWII_Predict[TWII_Predict[,2]==4,1],on=1,type="p",col=8,pch=22)
addTA(TWII_Predict[TWII_Predict[,2]==5,1],on=1,type="p",col=10,pch=21)
change <- sum(hm_model$HMM$transMat[last(VitPath$states),] * .colSums((matrix(unlist(hm_model$HMM$distribution$mean),nrow=4,ncol=5)) * (matrix(unlist(hm_model$HMM$distribution$proportion), nrow=4,ncol=5)), m=4,n=5))
mydata <- last(TWII_Subset)
predict <- mydata$TWII.Open + change
predict$TWII.Open
mydata
library(genalg)
library(ggplot2)
library(animation)
# Create the table for the knapsack problem.
dataset <- data.frame(item = c("pocketknife", "beans", "potatoes",
"unions", "sleeping bag", "rope", "compass"),
survivalpoints = c(10, 20, 15, 2, 30, 10, 30),
weight = c(1, 5, 10, 1, 7, 5, 1))
# Create a variable to represent the maximum weightlimit.
weightlimit <- 20
View(dataset)
chromosome = c(1, 0, 0, 1, 1, 0, 0)
dataset[chromosome == 1, ]
# We can check to what amount of surivival points this configuration sums up.
cat(chromosome %*% dataset$survivalpoints)
evalFunc <- function(x) {
current_solution_survivalpoints <- x %*% dataset$survivalpoints
current_solution_weight <- x %*% dataset$weight
if (current_solution_weight > weightlimit)
return(0) else return(-current_solution_survivalpoints)
}
iter = 100
GAmodel <- rbga.bin(size = 7, popSize = 200, iters = 100, mutationChance = 0.01,
elitism = T, evalFunc = evalFunc)
cat(summary.rbga(GAmodel))
solution = c(1, 1, 0, 1, 1, 1, 1)
dataset[solution == 1, ]
library("GA")
data("fat", package="UsingR")
mydata <- fat
View(mydata)
model <- lm(body.fat.siri ~ age + weight + height + neck + chest + abdomen
+ hip + thigh + knee + ankle + bicep + forearm + wrist, data=mydata)
summary(model)
library("GA")
# The design matrix without the intercept is extracted from the
# fitted model object by:
x <- model.matrix(model)[,-1]
y <- model.response(model.frame(model))
# Then the fitness function can be maximized by the following:
fitness <- function(string){
inc <- which(string == 1)
X <- cbind(1, x[,inc])
mod <- lm.fit(X,y)
class(mod) <- "lm"
-AIC(mod)
}
GA <- ga("binary", fitness = fitness, nBits = ncol(x), names= colnames(x), monitor=plot)
plot(GA)
summary(GA)
model2 <- lm(body.fat.siri~.,
data=data.frame(body.fat.siri = y, x[,GA@solution == 1]))
summary(model2)
library(GA)
data(airquality)
airquality <- na.omit(airquality)
View(airquality)
OLS <- function(data, b0, b1, b2){
attach(data, warn.conflicts=F)
Y_hat <- b0  + b1*Wind + b2*Temp
SSE = t(Ozone-Y_hat) %*% (Ozone-Y_hat) #matrix formulation for SSE
detach(data)
return(SSE)
}
ga.OLS <- ga(type='real-valued', min=c(-100,-100, -100),
max=c(100, 100, 100), popSize=500, maxiter=500, names=c('intercept', 'Wind', 'Temp'),
keepBest=T, fitness = function(b) -OLS(airquality, b[1],b[2], b[3]))
ga.model <- summary(ga.OLS)
ga.model
plot(ga.model)
lm.model <- lm(formula= Ozone ~ Wind + Temp, data=airquality)
summary(lm.model)
lm.model$res %*% lm.model$res ### SSE.lm
-ga.model$fitness ### SSE.ga
lm.model$res %*% lm.model$res + ga.model$fitness  ### difference between OLS and GA's SSE
setwd("C:/Users/Derek/Documents/RPackages/Time Series")
kings <- scan("http://robjhyndman.com/tsdldata/misc/kings.dat",skip=3)
kingstimeseries <- ts(kings)
setwd("C:/Users/Derek/Documents/RPackages/Time Series")
######################################################################
kings <- scan("http://robjhyndman.com/tsdldata/misc/kings.dat",skip=3)
kingstimeseries <- ts(kings)
kings
kingstimeseries
library("TTR")
kingstimeseriesSMA3 <- SMA(kingstimeseries,n=3)
kingstimeseriesSMA8 <- SMA(kingstimeseries,n=8)
kingtimeseriesdiff1 <- diff(kingstimeseries, differences=1)
library("forecast") # load the "forecast" R library
kingstimeseriesarima <- arima(kingstimeseries, order=c(0,1,1)) # fit an ARIMA(0,1,1) model
kingstimeseriesforecasts <- forecast.Arima(kingstimeseriesarima, h=5)
kingstimeseriesforecasts
births <- scan("http://robjhyndman.com/tsdldata/data/nybirths.dat")
birthstimeseries <- ts(births, frequency=12, start=c(1946,1))
birthstimeseriescomponents <- decompose(birthstimeseries)
plot(birthstimeseriescomponents)
setwd("C:/Users/Derek/Documents/RPackages/Neural Network")
############################################################################
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# Load Libraries
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
library("neuralnet")
library("car")
library("caret")
data(Hartnagel)
mydata <- Hartnagel
attach(mydata)
View(mydata)
NNTrain  <- avNNet(fconvict ~ tfr + partic + degrees + mconvict, data=mydata,
repeats=25, size=5, decay=0.3,linout=TRUE)
testdata <- mydata
testdata$Prediction <- predict(NNTrain, mydata)
View(testdata)
library("neuralnet")
library("car")
library("caret")
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# Load the Hartnagel dataset from the Car package
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
data(Hartnagel)
mydata <- Hartnagel
attach(mydata)
setwd("C:/Users/Derek/Documents/RPackages/Neural Network")
View(mydata)
NNTrain  <- avNNet(fconvict ~ year, data=mydata,
repeats=25, size=5, decay=0.3,linout=TRUE)
testdata <- mydata
testdata$Prediction <- predict(NNTrain, mydata)
write.csv(testdata, file='C:/Users/Derek/Documents/RPackages/Neural Network/ResultsTime.csv', row.names=F)
setwd("C:/Users/Derek/Documents/RPackages/Neural Network")
library("neuralnet")
library("car")
library("caret")
data(Hartnagel)
mydata <- Hartnagel
attach(mydata)
View(mydata)
