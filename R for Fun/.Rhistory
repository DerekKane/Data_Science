library(rcom)
comRegisterRegistry()
# Here is the map tutorial for drawing basic maps, etc...
setwd("C:/Users/kane.de/Documents/RPackages/Map Tutorial")
#install.packages("rworldmap")
library(rworldmap)
# start with the entire world
newmap <- getMap(resolution = "low")
plot(newmap, main = "World")
#crop to the area desired (outside US)
# (can use maps.google.com, right-click, drop lat/lon markers at corners)
plot(newmap
, xlim = c(-139.3, -58.8) # if you reverse these, the world gets flipped
, ylim = c(13.5, 55.7)
, asp = 1 # different aspect projections
, main = "US from worldmap")
#############################################################################
library(ggplot2)
map.world <- map_data(map = "world")
# map = name of map provided by the maps package.
# These include county, france, italy, nz, state, usa, world, world2.
str(map.world)
# how many regions
length(unique(map.world$region))
# how many group polygons (some regions have multiple parts)
length(unique(map.world$group))
p1 <- ggplot(map.world, aes(x = long, y = lat, group = group))
p1 <- p1 + geom_polygon() # fill areas
p1 <- p1 + labs(title = "World, plain")
#print(p1)
p2 <- ggplot(map.world, aes(x = long, y = lat, group = group, colour = region))
p2 <- p2 + geom_polygon() # fill areas
p2 <- p2 + theme(legend.position="none") # remove legend with fill colours
p2 <- p2 + labs(title = "World, colour borders")
#print(p2)
p3 <- ggplot(map.world, aes(x = long, y = lat, group = group, fill = region))
p3 <- p3 + geom_polygon() # fill areas
p3 <- p3 + theme(legend.position="none") # remove legend with fill colours
p3 <- p3 + labs(title = "World, filled regions")
#print(p3)
p4 <- ggplot(map.world, aes(x = long, y = lat, group = group, colour = region))
p4 <- p4 + geom_path() # country outline, instead
p4 <- p4 + theme(legend.position="none") # remove legend with fill colours
p4 <- p4 + labs(title = "World, path outlines only")
#print(p4)
#install.packages("gridExtra")
library(gridExtra)
grid.arrange(p1, p2, p3, p4, ncol=2, main="ggmap examples")
#############################################################################
#install.packages("ggmap")
#install.packages("mapproj")
library(ggmap)
library(mapproj)
map <- get_map(location = "New Mexico", zoom = 7, maptype = "hybrid")
# Location is the google search string
# Zoom = larger is closer
# maptype = google map type
## Map from URL : http://maps.googleapis.com/maps/api/staticmap?center=New+Mexico&zoom=7&size=%20640x640&scale=%202&maptype=hybrid&sensor=false
## Google Maps API Terms of Service : http://developers.google.com/maps/terms
## Information from URL : http://maps.googleapis.com/maps/api/geocode/json?address=New+Mexico&sensor=false
p <- ggmap(map)
p <- p + labs(title = "NM hybrid")
print(p)
# some options are cute, but not very informative
map <- get_map(location = "Albuquerque, New Mexico", zoom = 10, maptype = "watercolor")
p <- ggmap(map)
p <- p + labs(title = "Albuquerque watercolor")
print(p)
#############################################################################
# Can we add some data points to a map?
dat <- read.table(text = "
location lat long
MathStat 35.08396 -106.62410
Ducks 35.08507 -106.62238
SC1Class 35.08614 -106.62349
Biology 35.08243 -106.62296
CSEL 35.08317 -106.62414
", header = TRUE)
## Sometimes the watercolor style can look nice.
# get map layer
map <- get_map(
location = "University of New Mexico", zoom = 16, maptype = "watercolor")
# plot map
p <- ggmap(map)
p <- p + geom_point(data = dat, aes(x = long, y = lat, shape = location, colour = location)
, size = 7)
p <- p + geom_text(data = dat, aes(x = long, y = lat, label = location), hjust = -0.2)
# legend positioning, removing grid and axis labeling
p <- p + theme( legend.position = "none" # remove legend
, panel.grid.major = element_blank()
, panel.grid.minor = element_blank()
, axis.text = element_blank()
, axis.title = element_blank()
, axis.ticks = element_blank()
)
p <- p + labs(title = "UNM SC1 locations")
print(p)
#############################################################################
# Lets say I started in my office in Math & Stat,
# then visited with the Ducks,
# then taught the SC1 class,
# then walked over to Biology,
# then finished by picking up a book in the CSEL library.
## Satellite view with points plotted from get_googlemap()
# the points need to be called "x" and "y" to get the google markers and path
dat.pts <- data.frame(x = dat$long, y = dat$lat)
# get map layer
map <- get_googlemap(
"University of New Mexico" # google search string
, zoom = 16 # larger is closer
, maptype = "satellite" # map type
, markers = dat.pts # markers for map
, path = dat.pts # path, in order of points
, scale = 2
)
# plot map
p <- ggmap(map
, extent = "device" # remove white border around map
, darken = 0.2 # darken map layer to help points stand out
)
p <- p + geom_text(data = dat, aes(x = long, y = lat, label = location)
, hjust = -0.2, colour = "white", size = 6)
# legend positioning, removing grid and axis labeling
p <- p + theme( legend.position = c(0.05, 0.05) # put the legend inside the plot area
, legend.justification = c(0, 0)
, legend.background = element_rect(colour = F, fill = "white")
, legend.key = element_rect(fill = F, colour = F)
, panel.grid.major = element_blank()
, panel.grid.minor = element_blank()
, axis.text = element_blank()
, axis.title = element_blank()
, axis.ticks = element_blank()
)
p <- p + labs(title = "UNM Walk around campus")
print(p)
#############################################################################
# Biking to a coffee shop example. We will put a couple of coffee shop examples
# and determine the distances to each one.
# enter the addresses
coffee.shops <- read.csv(text = "
Name|Address
Annapurnas World Vegetarian Cafe|2201 Silver Avenue Southeast, Albuquerque, NM 87106
Dunkin Donuts|1902 Central Avenue Southeast, Albuquerque, NM 87106
Flying Star Cafe|3416 Central Avenue Southeast, Albuquerque, NM 87106
Limonata|3220 Silver Avenue Southeast, Albuquerque, NM 87106
Satellite Coffee|2300 Central Avenue Southeast, Albuquerque, New Mexico 87106
Satellite Coffee|3513 Central Avenue Northeast, Albuquerque, NM 87106
Starbucks|3400 Central Avenue Southeast, Albuquerque, NM 87106
Winning Coffee Co.|111 Harvard Drive Southeast, Albuquerque, NM 87106
", sep = "|", strip.white = TRUE, stringsAsFactors = FALSE)
coffee.shops
# location for Math & Stat building
home <- c(-106.624147, 35.083921)
#install.packages("scales")
#install.packages("plyr")
library(plyr)
cs.dist <- ddply(coffee.shops, .(Name,Address)
, .fun = function(X) {
map.dist <- mapdist(from = home
, to = X$Address
, mode = "bicycling"
, output = "all"
)
out <- data.frame(distance.text = map.dist[[1]][[1]]$distance$text
, distance.value = map.dist[[1]][[1]]$distance$value
, duration.text = map.dist[[1]][[1]]$duration$text
, duration.value = map.dist[[1]][[1]]$duration$value)
})
# How many more distance queries do I have left? Google has a limit.
distQueryCheck()
# center the map at Central and Girard
map.center <- data.frame(lon = -106.6133, lat = 35.0811)
# geocode the lat/lon, though geocode returns lon/lat (for x,y order)
map.coffee <- geocode(cs.dist$Address)
map.coffee
# bind together
cs.dist2 <- cbind(cs.dist, map.coffee)
df.home <- data.frame("Math&Stat"
, "University of New Mexico"
, NA, NA, NA, NA
, home[1]
, home[2])
colnames(df.home) <- colnames(cs.dist2)
# add our home to the df
cs.dist3 <- rbind(cs.dist2, df.home)
# get map layer
map <- get_googlemap(
center = as.numeric(map.center)
, zoom = 15 # larger is closer
, maptype = "roadmap" # map type
, markers = cs.dist3[,c("lon","lat")] # markers for map
, scale = 2
)
# plot map
p <- ggmap(map, extent = "device", darken = 0)
p <- p + geom_rect(data = cs.dist3, aes(xmin = lon, ymin = lat, xmax = lon+.004, ymax = lat+.001, fill = duration.value, colour = distance.value), size = 1)
# Labels
p <- p + geom_text(data = cs.dist3, aes(x = lon, y = lat, label = Name)
, hjust = 0, vjust = -1, size = 3, colour = "white")
# legend positioning, removing grid and axis labeling
p <- p + theme( panel.grid.major = element_blank()
, panel.grid.minor = element_blank()
, axis.text = element_blank()
, axis.title = element_blank()
, axis.ticks = element_blank()
)
p <- p + labs(title = "UNM Bike to Coffee shops")
print(p)
#############################################################################
# Study of crimes in Houston
library(scales) # for muted graphics
str(crime)
# Extract location of crimes in houston
violent_crimes <- subset(crime, ((offense != "auto theft")
& (offense != "theft")
& (offense != "burglary")))
# rank violent crimes
violent_crimes$offense <- factor(violent_crimes$offense
, levels = c("robbery", "aggravated assault"
, "rape", "murder"))
# restrict to downtown
violent_crimes <- subset(violent_crimes, ((-95.39681 <= lon)
& (lon <= -95.34188)
& (29.73631 <= lat)
& (lat <= 29.784)))
map <- get_map( location = "Houston TX"
, zoom = 14
, maptype = "roadmap"
, color = "bw" # make black & white so color is data
)
p <- ggmap(map)
p <- p + geom_point(data = violent_crimes
, aes(x = lon, y = lat, size = offense, colour = offense))
# legend positioning, removing grid and axis labeling
p <- p + theme( legend.position = c(0.0, 0.7) # put the legend inside the plot area
, legend.justification = c(0, 0)
, legend.background = element_rect(colour = F, fill = "white")
, legend.key = element_rect(fill = F, colour = F)
, panel.grid.major = element_blank()
, panel.grid.minor = element_blank()
, axis.text = element_blank()
, axis.title = element_blank()
, axis.ticks = element_blank()
)
print(p)
#############################################################################
theme_set(theme_bw(16))
HoustonMap <- qmap("houston", zoom = 14, color = "bw", legend = "topleft")
HoustonMap +
geom_point(aes(x = lon, y = lat, colour = offense, size = offense),
data = violent_crimes)
HoustonMap +
stat_bin2d(
aes(x = lon, y = lat, colour = offense, fill = offense),
size = .5, bins = 30, alpha = 1/2,
data = violent_crimes
)
#############################################################################
# 2D density plot
p <- ggmap(map)
overlay <- stat_density2d(data = violent_crimes
, aes(x = lon, y = lat, fill = ..level.. , alpha = ..level..)
, size = 2, bins = 4, geom = "polygon")
p <- p + overlay
p <- p + scale_fill_gradient2("Violent Crime Density", low = "white", mid = "yellow", high = "red")
p <- p + scale_alpha(range = c(0.4, 0.75), guide = FALSE)
p <- p + guides(fill = guide_colorbar(barwidth = 1.5, barheight = 10))
#p <- p + inset(grob = ggplotGrob(ggplot() + overlay + theme_inset())
# , xmin = -95.35836, xmax = Inf, ymin = -Inf, ymax = 29.75062)
print(p)
# now lets do it by day of week
p <- p + facet_wrap( ~ day, nrow = 2)
print(p)
#############################################################################
# Study of Minard's map using ggplot
library(ggplot2)
library(plyr)
troops <- read.table("http://stat405.had.co.nz/data/minard-troops.txt", header=T)
cities <- read.table("http://stat405.had.co.nz/data/minard-cities.txt", header=T)
russia <- map_data("world", region = "USSR")
p <- ggplot(troops, aes(long, lat))
p <- p + geom_polygon(data = russia, aes(x = long, y = lat, group = group)
, fill = "white")
p <- p + geom_path(aes(size = survivors, colour = direction, group = group)
, lineend = "round")
p <- p + geom_text(data = cities, aes(label = city), size = 3)
p <- p + scale_size(range = c(1, 6)
, breaks = c(1, 2, 3) * 10^5
, labels = c(1, 2, 3) * 10^5)
p <- p + scale_colour_manual(values = c("bisque2", "grey10"))
p <- p + xlab(NULL)
p <- p + ylab(NULL)
p <- p + coord_equal(xlim = c(20, 40), ylim = c(50, 60))
print(p)
#############################################################################
# Choropleth maps tutorial
# A choropleth map is a thematic map in which areas are shaded or patterned
# in proportion to the measurement of the statistical variable being displayed
# on the map, such as population density or per-capita income. The choropleth
# map provides an easy way to visualize how a measurement varies across a
# geographic area or it shows the level of variability within a region.
library(maps)
library(ggplot2)
library(plyr)
# make fake choropleth data
newmexico <- map("county", regions = "new mexico", plot = FALSE, fill = TRUE)
newmexico <- fortify(newmexico)
newmexico <- ddply(newmexico, "subregion", function(df){
mutate(df, fake = rnorm(1))
})
# make standard ggplot map (without geom_map)
p <- ggplot(newmexico, aes(x = long, y = lat, group = group, fill = fake))
p <- p + geom_polygon(colour = "white", size = 0.3)
print(p)
# Now, a fancier map using ggmap...
library(ggmap)
p <- qmap('New Mexico', zoom = 7, maptype = 'satellite', legend = 'topleft')
p <- p + geom_polygon(data = newmexico
, aes(x = long, y = lat, group = group, fill = fake)
, color = 'white'
, alpha = .75, size = .2)
# Add some city names, by looking up their location
cities <- c("Albuquerque NM", "Las Cruces NM", "Rio Rancho NM", "Santa Fe NM",
"Roswell NM", "Farmington NM", "South Valley NM", "Clovis NM",
"Hobbs NM", "Alamogordo NM", "Carlsbad NM", "Gallup NM", "Los Alamos NM")
cities_locs <- geocode(cities)
cities_locs$city <- cities
p <- p + geom_text(data = cities_locs, aes(label = city)
, color = 'yellow'
, size = 3)
print(p)
#############################################################################
# This is a tutorial to build useful maps from crime data
# the data comes from http://www.crimemapping.com/default.aspx
NMcrime <- read.csv("http://statacumen.com/teach/SC1/SC1_16_crimemapping_Theft2013Q1.csv"
, header = FALSE, skip = 11, stringsAsFactors = FALSE
, col.names = c("Type", "Description", "Case", "Location", "Agency", "Date"))
NMcrime$CityState <- "Albuquerque NM"
NMcrime$Address <- paste(NMcrime$Location, NMcrime$CityState)
# geocode the lat/lon, though geocode returns lon/lat (for x,y order)
# Note, I include "warning=FALSE, message=FALSE" in the knitr options
# to supress all the Google Maps API messages in the output.
ll.NMcrime <- geocode(NMcrime$Address)
NMcrime2 <- cbind(NMcrime, ll.NMcrime)
write.csv(NMcrime2, file = "NMcrime2.csv")
# This is the code in case we want to check if there is a file first.
# This avoids having to open the google api for each data point.
## fn.NMcrime2 <- "C:/Users/kane.de/Documents/RPackages/Map Tutorial"
## if (file.exists(fn.NMcrime2)) {
## # if this file exists, then weve already done the geocode(),
## # just read the file
## NMcrime2 <- read.csv(fn.NMcrime2, stringsAsFactors = FALSE)
## } else {
## # otherwise, read the original file and do the geocode() and write the file
## NMcrime <- read.csv("http://statacumen.com/teach/SC1/SC1_16_crimemapping_Theft2013Q1.csv"
##                     , header = FALSE, skip = 11, stringsAsFactors = FALSE
##                     , col.names = c("Type", "Description", "Case", "Location", "Agency", "Date"))
## NMcrime$CityState <- "Albuquerque NM"
## NMcrime$Address <- paste(NMcrime$Location, NMcrime$CityState)
## # geocode the lat/lon, though geocode returns lon/lat (for x,y order)
## # Note, I include "warning=FALSE, message=FALSE" in the knitr options
## # to supress all the Google Maps API messages in the output.
## ll.NMcrime <- geocode(NMcrime$Address)
## NMcrime2 <- cbind(NMcrime, ll.NMcrime)
## # Since it takes a while to geocode many addresses,
## # save this output to a file that can be read in conveniently as you
## # develop the code below.
## write.csv(NMcrime2, fn.NMcrime2, row.names = FALSE)
## }
# Remove an outlier (large lon)
NMcrime2 <- NMcrime2[-which(NMcrime2$lon == max(NMcrime2$lon)),]
NMcrime2$Description <- factor(NMcrime2$Description)
# day of week
day.temp <- weekdays(as.Date(NMcrime2$Date, format = "%m/%d/%Y %H:%M"))
NMcrime2$day <- factor(day.temp, levels = rev(unique(day.temp)), ordered = TRUE)
# time of day
time.temp <- as.POSIXct(NMcrime2$Date, format = "%m/%d/%Y %H:%M")
# convert time to 6-hour blocks
NMcrime2$time <- cut(as.POSIXlt(time.temp)$hour, c(0,6,12,18,24))
# Lets build a map
map <- get_map( location = "Lomas/Girard Albuquerque NM"
, zoom = 14
, maptype = "roadmap"
, color = "bw" # make black & white so color is data
)
# This will integrate the data set as points on the map.
p <- ggmap(map)
p <- p + geom_point(data = NMcrime2
, aes(x = lon, y = lat, colour = Description)
, alpha = 0.5, size = 2
, position = "jitter")
print(p)
# This will create a 2D density map.
p <- ggmap(map)
p <- p + scale_x_continuous(expand = c(0.05, 0)) # expand axes 5%
p <- p + scale_y_continuous(expand = c(0.05, 0)) # before creating the overlay
# Overlay the datapoints on the map.
overlay <- stat_density2d(data = NMcrime2
, aes(x = lon, y = lat, fill = ..level.. , alpha = ..level..)
, size = 1, bins = 10, geom = "polygon")
p <- p + overlay
p <- p + scale_fill_gradient("Density")
p <- p + scale_alpha(range = c(0.1, 0.3), guide = FALSE)
p <- p + guides(fill = guide_colorbar(barwidth = 1.5, barheight = 16))
p <- p + geom_point(data = NMcrime2
, aes(x = lon, y = lat, colour = Description)
, alpha = 0.5, size = 2
, position = "jitter")
p <- p + labs(title = "Burglary and theft 2013 Q1")
print(p)
# By day of the week
p1 <- p + facet_wrap( ~ day, nrow = 2)
p1 <- p1 + labs(title = "Burglary and theft 2013 Q1, by weekday")
print(p1)
# By time of the day
p2 <- p + facet_wrap( ~ time, nrow = 2)
p2 <- p2 + labs(title = "Burglary and theft 2013 Q1, by time of day")
print(p2)
View(NMcrime)
install.packages("RFacebook")
install.packages("Rfacebook")
install.packages("Rook")
require("Rfacebook")
fb_oauth <- fbOAuth(app_id="276998682477068", app_secret="2ecc57d5e314def99430231eda698185")
setwd("C:/Users/Derek/Documents/RPackages/R for Fun")
main = read.csv("2012-drugs-related-cx.csv")
pop = read.csv("scotland pop by ca.csv")
crime = read.csv("most_deprived_datazones_by_council_(crime)_2012.csv")
edu = read.csv("most_deprived_datazones_by_council_(education)_2012.csv")
emp = read.csv("most_deprived_datazones_by_council_(employment)_2012.csv")
health = read.csv("most_deprived_datazones_by_council_(health)_2012.csv")
income = read.csv("most_deprived_datazones_by_council_(income)_2012.csv")
names(main)
main$Council.area
main$Council.area[1:10]
main[1:10,1]
main = merge(main, pop[,c(2,3)], by.x="Council.area", by.y="Council.area", all.x=TRUE)
main = merge(main, crime[,c(1,4)], by.x="Council.area", by.y="label", all.x=TRUE)
main = merge(main, edu[,c(1,4)], by.x="Council.area", by.y="label", all.x=TRUE)
main = merge(main, emp[,c(1,4)], by.x="Council.area", by.y="label", all.x=TRUE)
main = merge(main, health[,c(1,4)], by.x="Council.area", by.y="label", all.x=TRUE)
main = merge(main, income[,c(1,4)], by.x="Council.area", by.y="label", all.x=TRUE)
main$All.drug.related.deaths_perTenK = (main$All.drug.related.deaths / (main$Population/10000))
hist(main$All.drug.related.deaths_perTenK, col="royal blue")
plot(All.drug.related.deaths_perTenK ~ prop_income, data=main)
pairs(~All.drug.related.deaths_perTenK + Latitude + Longitude + prop_crime + prop_education + prop_employment + prop_income + prop_health, data=main)
summary(main)
mean(main$All.drug.related.deaths)
median(main$All.drug.related.deaths_perTenK)
main$LongSplit = cut(main$Longitude, breaks=quantile(main$Longitude, c(0,.5,1)), include.lowest=TRUE, right=FALSE, ordered_result=TRUE, labels=c("East", "West"))
table(main$LongSplit)
main$LatSplit = cut(main$Latitude, breaks=quantile(main$Latitude, c(0,.5,1)), include.lowest=TRUE, right=FALSE, ordered_result=TRUE, labels=c("South", "North"))
install.package(dplyr)
install.packages(dplyr)
install.packages("dplyr")
library(dplyr)
data_source = collect(main)
grouping_factors = group_by(source_df, LongSplit, LatSplit)
deaths_by_area = summarise(grouping_factors, median.deathsptk = median(All.drug.related.deaths_perTenK),
median.crime = median(prop_crime), median.emp = median(prop_employment),
median.edu = median(prop_education), num.council.areas = length(All.drug.related.deaths_perTenK))
deaths_by_area
data_source = collect(main)
grouping_factors = group_by(source_df, LongSplit, LatSplit)
install.packages("likert")
install.packages("ggthemes")
install.packages("plyr")
install.packages("scales")
ltep = read.csv("ltep-survey-results-all.csv")
library(likert)
library(ggthemes)
# Here I flip the scoring
ltep[,13:19] = sapply(ltep[,13:19], function (x) 8 - x)
deal.w.esources = likert(ltep[,13:19])
summary(deal.w.esources)
plot(deal.w.esources, text.size=6, text.color="black") + theme(axis.text.x=element_text(colour="black", face="bold", size=14), axis.text.y=element_text(colour="black", face="bold", size=14), axis.title.x=element_text(colour="black", face="bold", size=14), plot.title=element_text(size=18, face="bold")) + ggtitle("What guidelines should Ontario use\n for its future mix of energy sources?")
library(likert)
library(ggthemes)
ltep[,13:19] = sapply(ltep[,13:19], function (x) 8 - x)
deal.w.esources = likert(ltep[,13:19])
summary(deal.w.esources)
library(plyr)
self.sustaining.region.by.nuke = ddply(ltep, .(Nuclear.power.is.our.best.option.), function (x) mean(x$A.region.should.be.responsible.for.generating.at.least.some.of.its.own.power. == "Agree", na.rm=TRUE))
self.sustaining.region.by.nuke = self.sustaining.region.by.nuke[1:7,]
region.buy.power.by.nuke = ddply(ltep, .(Nuclear.power.is.our.best.option.), function (x) mean(x$Regions.should.have.the.option.to.buy.all.of.their.power.from.sources.in.another.region..if.the.power.is.available. == "Agree", na.rm=TRUE))
region.buy.power.by.nuke = region.buy.power.by.nuke[1:7,]
region.resp.for.growing.demand.by.nuke = ddply(ltep, .(Nuclear.power.is.our.best.option.), function (x) mean(x$If.a.region.s.power.demand.is.growing..it.should.be.responsible.for.building.the.generation.or.transmission.to.supply.that.it.needs. == "Agree", na.rm=TRUE))
region.resp.for.growing.demand.by.nuke = region.resp.for.growing.demand.by.nuke[1:7,]
regions.make.cons.first.priority.by.nuke = ddply(ltep, .(Nuclear.power.is.our.best.option.), function (x) mean(x$Regions.should.make.conservation.their.first.priority.to.reduce.the.need.for.new.supply. == "Agree", na.rm=TRUE))
regions.make.cons.first.priority.by.nuke = regions.make.cons.first.priority.by.nuke[1:7,]
# Here's the green energy section
self.sustaining.region.by.green = ddply(ltep, .(Green.energy..e.g...wind..solar..is.our.best.option.), function (x) mean(x$A.region.should.be.responsible.for.generating.at.least.some.of.its.own.power. == "Agree", na.rm=TRUE))
self.sustaining.region.by.green = self.sustaining.region.by.green[1:7,]
region.buy.power.by.green = ddply(ltep, .(Green.energy..e.g...wind..solar..is.our.best.option.), function (x) mean(x$Regions.should.have.the.option.to.buy.all.of.their.power.from.sources.in.another.region..if.the.power.is.available. == "Agree", na.rm=TRUE))
region.buy.power.by.green= region.buy.power.by.green[1:7,]
region.resp.for.growing.demand.by.green = ddply(ltep, .(Green.energy..e.g...wind..solar..is.our.best.option.), function (x) mean(x$If.a.region.s.power.demand.is.growing..it.should.be.responsible.for.building.the.generation.or.transmission.to.supply.that.it.needs. == "Agree", na.rm=TRUE))
region.resp.for.growing.demand.by.green = region.resp.for.growing.demand.by.green[1:7,]
regions.make.cons.first.priority.by.green = ddply(ltep, .(Green.energy..e.g...wind..solar..is.our.best.option.), function (x) mean(x$Regions.should.make.conservation.their.first.priority.to.reduce.the.need.for.new.supply. == "Agree", na.rm=TRUE))
regions.make.cons.first.priority.by.green = regions.make.cons.first.priority.by.green[1:7,]
# in this section I alternate between getting each data frame ready for plotting
# and obviously plotting the data frame.  I liked the yellow and green that I used in the plot
# to represent Nuclear vs. Green energy :)
library(ggplot2)
library(scales)
self.sustaining.region = rbind(data.frame(Importance=seq(1,7),Pct.Agree=self.sustaining.region.by.nuke$V1, Energy=rep("Nuclear Energy",7)), data.frame(Importance=seq(1,7),Pct.Agree=self.sustaining.region.by.green$V1, Energy=rep("Green Energy", 7)))
ggplot(self.sustaining.region, aes(x=as.factor(Importance), y=Pct.Agree, fill=Energy)) + geom_bar(stat="identity",width=.5) + scale_y_continuous(labels=percent, name="Percent Who Agree") + scale_x_discrete(name="Rated Level of Importance (1-7 = Low to High)") +  facet_grid(~Energy) + scale_fill_manual(values=c("khaki1","forest green")) + ggtitle("A Region Should be Responsible for Generating at Least Some of Its Own Power\n(Agreement by Rated Importance of Nuclear vs. Green Energy)") + theme(axis.text.x=element_text(colour="black", face="bold", size=14), axis.text.y=element_text(colour="black", face="bold", size=14), axis.title.x=element_text(colour="black", face="bold", size=14), axis.title.y=element_text(colour="black", face="bold", size=14), plot.title=element_text(size=18, face="bold"), strip.text=element_text(size=14), legend.title=element_text(size=14), legend.text=element_text(size=14))
region.buy.power = rbind(data.frame(Importance=seq(1,7),Pct.Agree=region.buy.power.by.nuke$V1, Energy=rep("Nuclear Energy",7)), data.frame(Importance=seq(1,7),Pct.Agree=region.buy.power.by.green$V1, Energy=rep("Green Energy", 7)))
ggplot(region.buy.power, aes(x=as.factor(Importance), y=Pct.Agree, fill=Energy)) + geom_bar(stat="identity",width=.5) + scale_y_continuous(labels=percent, name="Percent Who Agree") + scale_x_discrete(name="Rated Level of Importance (1-7 = Low to High)") +  facet_grid(~Energy) + scale_fill_manual(values=c("khaki1","forest green")) + ggtitle("Regions Should Have the Option to Buy All of their Power\nfrom Sources in Another Region if Available\n(Agreement by Rated Importance of Nuclear vs. Green Energy)") + theme(axis.text.x=element_text(colour="black", face="bold", size=14), axis.text.y=element_text(colour="black", face="bold", size=14), axis.title.x=element_text(colour="black", face="bold", size=14), axis.title.y=element_text(colour="black", face="bold", size=14), plot.title=element_text(size=18, face="bold"), strip.text=element_text(size=14), legend.title=element_text(size=14), legend.text=element_text(size=14))
region.resp.for.growing.demand = rbind(data.frame(Importance=seq(1,7),Pct.Agree=region.resp.for.growing.demand.by.nuke$V1, Energy=rep("Nuclear Energy",7)), data.frame(Importance=seq(1,7),Pct.Agree=region.resp.for.growing.demand.by.green$V1, Energy=rep("Green Energy", 7)))
ggplot(region.resp.for.growing.demand, aes(x=as.factor(Importance), y=Pct.Agree, fill=Energy)) + geom_bar(stat="identity",width=.5) + scale_y_continuous(labels=percent, name="Percent Who Agree") + scale_x_discrete(name="Rated Level of Importance (1-7 = Low to High)") +  facet_grid(~Energy) + scale_fill_manual(values=c("khaki1","forest green")) + ggtitle("If a Region's Power Demand is Growing\nIt Should be Responsible for Building the Transmission/Supply it Needs\n(Agreement by Rated Importance of Nuclear vs. Green Energy)") + theme(axis.text.x=element_text(colour="black", face="bold", size=14), axis.text.y=element_text(colour="black", face="bold", size=14), axis.title.x=element_text(colour="black", face="bold", size=14), axis.title.y=element_text(colour="black", face="bold", size=14), plot.title=element_text(size=18, face="bold"), strip.text=element_text(size=14), legend.title=element_text(size=14), legend.text=element_text(size=14))
regions.make.cons.first.priority = rbind(data.frame(Importance=seq(1,7),Pct.Agree=regions.make.cons.first.priority.by.nuke$V1, Energy=rep("Nuclear Energy",7)), data.frame(Importance=seq(1,7),Pct.Agree=regions.make.cons.first.priority.by.green$V1, Energy=rep("Green Energy", 7)))
ggplot(regions.make.cons.first.priority, aes(x=as.factor(Importance), y=Pct.Agree, fill=Energy)) + geom_bar(stat="identity",width=.5) + scale_y_continuous(labels=percent, name="Percent Who Agree") + scale_x_discrete(name="Rated Level of Importance (1-7 = Low to High)") +  facet_grid(~Energy) + scale_fill_manual(values=c("khaki1","forest green")) + ggtitle("Regions Should Make Conservation Their First Priority \nto Reduce the Need for New Supply\n(Agreement by Rated Importance of Nuclear vs. Green Energy)") + theme(axis.text.x=element_text(colour="black", face="bold", size=14), axis.text.y=element_text(colour="black", face="bold", size=14), axis.title.x=element_text(colour="black", face="bold", size=14), axis.title.y=element_text(colour="black", face="bold", size=14), plot.title=element_text(size=18, face="bold"), strip.text=element_text(size=14), legend.title=element_text(size=14), legend.text=element_text(size=14))
