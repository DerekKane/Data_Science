install.packages("ridge")
install.packages("glmnet")
install.packages("lasso2")
install.packages("colorspace")
install.packages("lars")
install.packages("elasticnet")
install.packages("MASS")
library(ridge)
library(glmnet)
library(lasso2)
library(colorspace)
library(lars)
library(elasticnet)
library(MASS)
data(Prostate)
mydata <- Prostate
View(mydata)
y <- as.numeric(Prostate[,9])
x <- as.matrix(Prostate[,1:8])
select(lm.ridge(lpsa~ lcavol + lweight + age + lbph + svi + lcp + gleason + pgg45,
data=mydata, lambda = seq(0,1,0.001)))
select(lm.ridge(lpsa~ lcavol + lweight + age + lbph + svi + lcp + gleason + pgg45,
data=mydata, lambda = seq(0,10,0.1)))
ridge.train <- lm.ridge(lpsa~ lcavol + lweight + age + lbph + svi + lcp + gleason + pgg45,
data=mydata, lambda = seq(0,10,0.1))
plot(seq(0,10,0.1), ridge.train$GCV, main="GCV of Ridge Regression", type="l",
xlab=expression(lambda), ylab="GCV")
lambda.ridge <- seq(0,10,0.1)[which.min(ridge.train$GCV)]
abline(v=lambda.ridge, lty=2, col="red")
colors <- rainbow_hcl(8, c = 65, l = 65) # 8 is the number or ind. variables
plot.new()
matplot(seq(0,10,0.1), coef(ridge.train)[,-1], xlim=c(0,11), type="l",xlab=expression(lambda),
ylab=expression(hat(beta)), col=colors, lty=1, lwd=2, main="Ridge coefficients")
abline(v=lambda.ridge, lty=2)
text(rep(10, 9), coef(ridge.train)[length(seq(0,10,0.1)),-1], colnames(mydata)[-9], pos=4, col=colors)
threshold <- seq(0,1000,0.1)
ridge.train2 <- lm.ridge(lpsa~ lcavol + lweight + age + lbph + svi + lcp + gleason + pgg45,
data=mydata, lambda = threshold)
colors <- rainbow_hcl(8, c = 65, l = 65) # 8 is the number or ind. variables
plot.new()
matplot(threshold, coef(ridge.train2)[,-1], xlim=c(0,1005), type="l",xlab=expression(lambda),
ylab=expression(hat(beta)), col=colors, lty=1, lwd=2, main="Ridge coefficients")
abline(v=lambda.ridge, lty=2)
text(rep(10, 9), coef(ridge.train2)[length(threshold),-1], colnames(mydata)[-9], pos=4, col=colors)
ridge.reg <- lm.ridge(lpsa~ lcavol + lweight + age + lbph + svi + lcp + gleason + pgg45,
data=mydata, lambda = lambda.ridge)
ridge.reg
pred.ridge <- coef(ridge.reg)[1] + coef(ridge.reg)[2]*mydata[,1] +
coef(ridge.reg)[3]*mydata[,2] + coef(ridge.reg)[4]*mydata[,3] +
coef(ridge.reg)[5]*mydata[,4] + coef(ridge.reg)[6]*mydata[,5] +
coef(ridge.reg)[7]*mydata[,6] + coef(ridge.reg)[8]*mydata[,7] +
coef(ridge.reg)[9]*mydata[,8]
mydata$YHat <- coef(ridge.reg)[1] + coef(ridge.reg)[2]*mydata[,1] +
coef(ridge.reg)[3]*mydata[,2] + coef(ridge.reg)[4]*mydata[,3] +
coef(ridge.reg)[5]*mydata[,4] + coef(ridge.reg)[6]*mydata[,5] +
coef(ridge.reg)[7]*mydata[,6] + coef(ridge.reg)[8]*mydata[,7] +
coef(ridge.reg)[9]*mydata[,8]
MSE.Ridge<-(sum((mydata$lpsa-pred.ridge)^2))/nrow(mydata)
# RMSE.Ridge<-sqrt((sum((mydata$lpsa-pred.ridge)^2))/nrow(mydata))
MSE.Ridge
lassoreg.cv <- cv.glmnet(x,y, alpha=1)
plot(lassoreg.cv)
lassoreg.cv$lambda.min
lassofits <- glmnet(x,y,alpha=1, nlambda=100)
plot(lassofits)
plot(lassofits, xvar = "lambda", label = TRUE)
plot(lassofits, xvar = "dev", label = TRUE)
lassopred <- predict(lassofits,x,s= lassoreg.cv$lambda.min)
# mydata$yhat <- predict(lassof
lassocoef <- predict(lassofits,x,s=lassoreg.cv$lambda.min, type="coefficients")
lassocoef
lassopred <- predict(lassofits,x,s= lassoreg.cv$lambda.min)
lassocoef <- predict(lassofits,x,s=lassoreg.cv$lambda.min, type="coefficients")
lassocoef
lassofits <- glmnet(x,y,alpha=1, nlambda=100)
plot(lassofits)
plot(lassofits, xvar = "lambda", label = TRUE)
plot(lassofits, xvar = "dev", label = TRUE)
lassopred <- predict(lassofits,x,s= lassoreg.cv$lambda.min)
lassocoef <- predict(lassofits,x,s=lassoreg.cv$lambda.min, type="coefficients")
lassocoef
sum1 =0
tt<-nrow(mydata) # testset
for (i in 1:tt){
sum1 <- sum1 + (lassopred[i]-mydata[i,9])^2
}
sumg <- sum1/tt
sumg
elasticreg.cv <- cv.glmnet(x,y, alpha=0.2)
plot(elasticreg.cv)
elasticreg.cv$lambda.min
elasticreg.cv$lambda.min
elasticfits <- glmnet(x,y,alpha=0.2, nlambda=100)
plot(elasticfits)
plot(elasticfits, xvar = "lambda", label = TRUE)
plot(elasticfits, xvar = "dev", label = TRUE)
elasticpred <- predict(elasticfits,x,s= elasticreg.cv$lambda.min)
elasticcoef <- predict(elasticfits,x,s=elasticreg.cv$lambda.min, type="coefficients")
elasticcoef
sum1 =0
tt<-nrow(mydata) # testset
for (i in 1:tt){
sum1 <- sum1 + (elasticpred[i]-mydata[i,9])^2
}
sumg <- sum1/tt
sumg
ridge.linreg<- lm(lpsa~ lcavol + lweight + age + lbph + svi + lcp + gleason + pgg45,
data=mydata)
summary(ridge.linreg)
ridge.linreg2<- lm(lpsa~ lcavol + lweight + svi,
data=mydata)
summary(ridge.linreg2)
linearpred <- predict(ridge.linreg2, newdata = mydata, type = "response")
sum1 =0
tt<-nrow(mydata) # testset
for (i in 1:tt){
sum1 <- sum1 + (linearpred[i]-mydata[i,9])^2
}
sumg <- sum1/tt
sumg
library(ridge)
library(glmnet)
library(lasso2)
library(colorspace)
library(lars)
library(elasticnet)
library(MASS)
data(Prostate)
mydata <- Prostate
y <- as.numeric(Prostate[,9])
x <- as.matrix(Prostate[,1:8])
select(lm.ridge(lpsa~ lcavol + lweight + age + lbph + svi + lcp + gleason + pgg45,
data=mydata, lambda = seq(0,1,0.001)))
lassoreg.cv <- cv.glmnet(x,y, alpha=1)
lassoreg.cv$lambda.min
lassofits <- glmnet(x,y,alpha=1, nlambda=100)
lassopred <- predict(lassofits,x,s= lassoreg.cv$lambda.min)
lassocoef <- predict(lassofits,x,s=lassoreg.cv$lambda.min, type="coefficients")
lassocoef
sum1 =0
tt<-nrow(mydata) # testset
for (i in 1:tt){
sum1 <- sum1 + (lassopred[i]-mydata[i,9])^2
}
sumg <- sum1/tt
sumg
lassofits <- glmnet(x,y,alpha=1, nlambda=100)
lassofits <- glmnet(x,y,alpha=1, nlambda=1000)
plot(lassofits)
plot(lassofits, xvar = "lambda", label = TRUE)
plot(lassofits, xvar = "dev", label = TRUE)
lassopred <- predict(lassofits,x,s= lassoreg.cv$lambda.min)
lassocoef <- predict(lassofits,x,s=lassoreg.cv$lambda.min, type="coefficients")
lassocoef
library(glmnet)
library(lasso2)
library(colorspace)
library(lars)
library(elasticnet)
data(Prostate)
mydata <- Prostate
y <- as.numeric(mydata[,9])
x <- as.matrix(mydata[,1:8])
model.lasso <- lars(x, y, type="lasso")
lambda.lasso <- c(model.lasso$lambda,0)
beta <- coef(model.lasso)
colors <- rainbow_hcl(8, c = 65, l = 65) # 8 is the number or ind. variables
matplot(lambda.lasso, beta, xlim=c(8,-2), type="o", pch=20, xlab=expression(lambda),
ylab=expression(hat(beta)), col=colors)
text(rep(-0, 9), beta[9,], colnames(x), pos=4, col=colors)
abline(v=lambda.lasso[4], lty=2)
abline(h=0, lty=2)
beta.scale <- attr(model.lasso$beta, "scaled:scale")
beta.rescaled <- beta
for(j in 1:9){
beta.rescaled[j,] <- beta.rescaled[j,]*beta.scale
}
matplot(lambda.lasso, beta.rescaled, xlim=c(8,-2), type="o", pch=20, xlab=expression(lambda),
ylab=expression(hat(beta)), col=colors)
text(rep(-0, 9), beta.rescaled[9,], colnames(x), pos=4, col=colors)
abline(v=lambda.lasso[4], lty=2)
abline(h=0, lty=2)
lassoreg.cv <- cv.glmnet(x,y, alpha=1)
plot(lassoreg.cv)
lassoreg.cv$lambda.min
lassofits <- glmnet(x,y,alpha=1, nlambda=100)
plot(lassofits)
plot(lassofits, xvar = "lambda", label = TRUE)
plot(lassofits, xvar = "dev", label = TRUE)
lassopred <- predict(lassofits,x,s= lassoreg.cv$lambda.min)
lassocoef <- predict(lassofits,x,s=lassoreg.cv$lambda.min, type="coefficients")
lassocoef
set.seed(123)
library(ridge)
library(glmnet)
library(lasso2)
library(colorspace)
library(lars)
library(elasticnet)
library(MASS)
data(Prostate)
mydata <- Prostate
y <- as.numeric(Prostate[,9])
x <- as.matrix(Prostate[,1:8])
select(lm.ridge(lpsa~ lcavol + lweight + age + lbph + svi + lcp + gleason + pgg45,
data=mydata, lambda = seq(0,1,0.001)))
select(lm.ridge(lpsa~ lcavol + lweight + age + lbph + svi + lcp + gleason + pgg45,
data=mydata, lambda = seq(0,10,0.1)))
ridge.train <- lm.ridge(lpsa~ lcavol + lweight + age + lbph + svi + lcp + gleason + pgg45,
data=mydata, lambda = seq(0,10,0.1))
plot(seq(0,10,0.1), ridge.train$GCV, main="GCV of Ridge Regression", type="l",
xlab=expression(lambda), ylab="GCV")
lambda.ridge <- seq(0,10,0.1)[which.min(ridge.train$GCV)]
abline(v=lambda.ridge, lty=2, col="red")
colors <- rainbow_hcl(8, c = 65, l = 65) # 8 is the number or ind. variables
plot.new()
matplot(seq(0,10,0.1), coef(ridge.train)[,-1], xlim=c(0,11), type="l",xlab=expression(lambda),
ylab=expression(hat(beta)), col=colors, lty=1, lwd=2, main="Ridge coefficients")
abline(v=lambda.ridge, lty=2)
text(rep(10, 9), coef(ridge.train)[length(seq(0,10,0.1)),-1], colnames(mydata)[-9], pos=4, col=colors)
threshold <- seq(0,1000,0.1)
ridge.train2 <- lm.ridge(lpsa~ lcavol + lweight + age + lbph + svi + lcp + gleason + pgg45,
data=mydata, lambda = threshold)
colors <- rainbow_hcl(8, c = 65, l = 65) # 8 is the number or ind. variables
plot.new()
matplot(threshold, coef(ridge.train2)[,-1], xlim=c(0,1005), type="l",xlab=expression(lambda),
ylab=expression(hat(beta)), col=colors, lty=1, lwd=2, main="Ridge coefficients")
abline(v=lambda.ridge, lty=2)
text(rep(10, 9), coef(ridge.train2)[length(threshold),-1], colnames(mydata)[-9], pos=4, col=colors)
ridge.reg <- lm.ridge(lpsa~ lcavol + lweight + age + lbph + svi + lcp + gleason + pgg45,
data=mydata, lambda = lambda.ridge)
# Printing the ridge-regression coefficient estimates for this problem:
ridge.reg
pred.ridge <- coef(ridge.reg)[1] + coef(ridge.reg)[2]*mydata[,1] +
coef(ridge.reg)[3]*mydata[,2] + coef(ridge.reg)[4]*mydata[,3] +
coef(ridge.reg)[5]*mydata[,4] + coef(ridge.reg)[6]*mydata[,5] +
coef(ridge.reg)[7]*mydata[,6] + coef(ridge.reg)[8]*mydata[,7] +
coef(ridge.reg)[9]*mydata[,8]
mydata$YHat <- coef(ridge.reg)[1] + coef(ridge.reg)[2]*mydata[,1] +
coef(ridge.reg)[3]*mydata[,2] + coef(ridge.reg)[4]*mydata[,3] +
coef(ridge.reg)[5]*mydata[,4] + coef(ridge.reg)[6]*mydata[,5] +
coef(ridge.reg)[7]*mydata[,6] + coef(ridge.reg)[8]*mydata[,7] +
coef(ridge.reg)[9]*mydata[,8]
MSE.Ridge<-(sum((mydata$lpsa-pred.ridge)^2))/nrow(mydata)
# RMSE.Ridge<-sqrt((sum((mydata$lpsa-pred.ridge)^2))/nrow(mydata))
MSE.Ridge
lassoreg.cv <- cv.glmnet(x,y, alpha=1)
plot(lassoreg.cv)
lassoreg.cv$lambda.min
lassofits <- glmnet(x,y,alpha=1, nlambda=100)
plot(lassofits)
plot(lassofits, xvar = "lambda", label = TRUE)
plot(lassofits, xvar = "dev", label = TRUE)
lassopred <- predict(lassofits,x,s= lassoreg.cv$lambda.min)
lassocoef <- predict(lassofits,x,s=lassoreg.cv$lambda.min, type="coefficients")
lassocoef
sum1 =0
tt<-nrow(mydata) # testset
for (i in 1:tt){
sum1 <- sum1 + (lassopred[i]-mydata[i,9])^2
}
sumg <- sum1/tt
sumg
library(neuralnet)
View(mydata)
View(mydata)
mydata$YHat <- NULL
set.seed(1234567890)
Churnnet <- neuralnet(lpsa ~ lcavol + lweight + age + lbph + svi + lcp + gleason + pgg45, mydata, hidden = 4, lifesign = "minimal",
linear.output = FALSE, learningrate = 0.3, threshold = 0.10, algorithm = "backprop", rep=2)
library(neuralnet)
install.packages(neuralnet)
install.packages("neuralnet")
library(neuralnet)
set.seed(1234567890)
Churnnet <- neuralnet(lpsa ~ lcavol + lweight + age + lbph + svi + lcp + gleason + pgg45, mydata, hidden = 4, lifesign = "minimal",
linear.output = FALSE, learningrate = 0.3, threshold = 0.10, algorithm = "backprop", rep=2)
Churnnet <- neuralnet(lpsa ~ lcavol + lweight + age + lbph + svi + lcp + gleason + pgg45, mydata, hidden = 4, lifesign = "minimal",
linear.output = FALSE, learningrate = 0.3, threshold = 0.10, algorithm = "backprop", rep=100)
plot(Churnnet, rep = "best")
NNResult <- compute(Churnnet, mydata[,1:8])
mydata$YHat4 <- NNResult$net.result[1]
View(mydata)
mydata$YHat4 <- NULL
set.seed(1234567890)
Churnnet <- neuralnet(lpsa ~ lcavol + lweight + age + lbph + svi + lcp + gleason + pgg45, mydata, hidden = 4, lifesign = "minimal",
linear.output = FALSE, learningrate = 0.3, threshold = 0.10, rep=100)
NNResult <- compute(Churnnet, mydata[,1:8])
mydata$YHat4 <- NNResult$net.result[1]
mydata
install.packages("caret")
library(caret)
NNet <- avNNet(lpsa ~ lcavol + lweight + age + lbph + svi + lcp + gleason + pgg45, data = mydata, repeats = 25, size=5, decay=0.3, linout=TRUE)
plot(NNet, rep = "best")
mydata$YHat4 <- predict(NNet, mydata)
mydata
setwd("C:/Users/Derek/Documents/RPackages/Business Metrics/")
setwd("C:/Users/dkane/Documents/R Scripts/Statistics/")
library(caret)
library(ggplot2)
mydata <- iris
mydata$Species <- NULL
clusterdata <- mydata
View(clusterdata)
scale(clusterdata, center = TRUE, scale = TRUE)
View(clusterdata)
clusterdata <- data.frame(lapply(clusterdata, function(x) scale(x, center = TRUE, scale = TRUE)
